{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "\n",
    "# Plot et Display\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Lecture des données \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_test = \"../../4A/Projet/Ensemble de test/\"\n",
    "path_test = \"../Donnees_projet/Ensemble_de_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('liste_propre', 'rb') as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    liste_propre, ind_recupere = mon_depickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(liste_propre)\n",
    "liste_appr = list(np.asarray(liste_propre)[np.asarray(ind_recupere) <= 299])\n",
    "liste_test = list(np.asarray(liste_propre)[np.asarray(ind_recupere) > 299])\n",
    "n_appr = len(liste_appr)\n",
    "n_test = len(liste_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom = [False] * n_test\n",
    "type_anom = [-1] * n_test\n",
    "loc = [-1] * n_test\n",
    "\n",
    "anom[73] = True\n",
    "type_anom[73] = 1\n",
    "loc[73] = 200\n",
    "\n",
    "anom[96] = True\n",
    "type_anom[96] = 1\n",
    "loc[96] = 300\n",
    "\n",
    "anom[36] = True\n",
    "type_anom[36] = 1\n",
    "loc[36] = 400\n",
    "\n",
    "anom[32] = True\n",
    "type_anom[32] = 1\n",
    "loc[32] = 300\n",
    "\n",
    "anom[33] = True\n",
    "type_anom[33] = 1\n",
    "loc[33] = 200\n",
    "\n",
    "anom[107] = True\n",
    "type_anom[107] = 2\n",
    "loc[107] = 600\n",
    "\n",
    "anom[60] = True\n",
    "type_anom[60] = 2\n",
    "loc[60] = 400\n",
    "\n",
    "anom[113] = True\n",
    "type_anom[113] = 2\n",
    "loc[113] = 400\n",
    "\n",
    "anom[9] = True\n",
    "type_anom[9] = 2\n",
    "loc[9] = 200\n",
    "\n",
    "anom[11] = True\n",
    "type_anom[11] = 2\n",
    "loc[11] = 300\n",
    "\n",
    "anom[53] = True\n",
    "type_anom[53] = 3\n",
    "loc[53] = 400\n",
    "\n",
    "anom[114] = True\n",
    "type_anom[114] = 3\n",
    "loc[114] = 400\n",
    "\n",
    "anom[14] = True\n",
    "type_anom[14] = 3\n",
    "loc[14] = 500\n",
    "\n",
    "anom[79] = True\n",
    "type_anom[79] = 3\n",
    "loc[79] = 400\n",
    "\n",
    "anom[29] = True\n",
    "type_anom[29] = 3\n",
    "loc[29] = 300\n",
    "\n",
    "anom[27] = True\n",
    "type_anom[27] = 4\n",
    "loc[27] = 300\n",
    "\n",
    "anom[121] = True\n",
    "type_anom[121] = 4\n",
    "loc[121] = 300\n",
    "\n",
    "anom[5] = True\n",
    "type_anom[5] = 4\n",
    "loc[5] = 400\n",
    "\n",
    "anom[89] = True\n",
    "type_anom[89] = 4\n",
    "loc[89] = 200\n",
    "\n",
    "anom[99] = True\n",
    "type_anom[99] = 4\n",
    "loc[99] = 100  \n",
    "\n",
    "anom = [False] * n_appr + anom\n",
    "type_anom = [-1] * n_appr + type_anom\n",
    "loc = [-1] * n_appr + loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_anom = list(np.where(np.asarray(anom))[0]) # Indices des anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fenetres(liste_comp, N, anom, loc):\n",
    "    serie = []\n",
    "    #origine = []\n",
    "    ind_debut = []\n",
    "    valeurs = []\n",
    "    anom_fen = []\n",
    "    for i, val, loc_i in zip(ind_recupere, liste_comp, loc):\n",
    "        # Liste des fenêtres de l'enregistrement\n",
    "        fenetres = [val[i * N:(i + 1) * N] for i in range((len(val) + N - 1) // N ) if len(val[i * N:(i + 1) * N]) == N]\n",
    "        nb_fen = len(fenetres)\n",
    "        valeurs += fenetres\n",
    "        anom_fen_i = [False] * nb_fen\n",
    "        pos_anom_deb_fen = loc_i // N\n",
    "        pos_anom_fin_fen = (loc_i + 55) // N\n",
    "        if loc_i > -1:\n",
    "            try:\n",
    "                for pos in range(pos_anom_deb_fen, pos_anom_fin_fen + 1):\n",
    "                    anom_fen_i[pos] = True\n",
    "\n",
    "            except IndexError:\n",
    "                pass\n",
    "                \"\"\"Cette erreur est levée lorsque l'anomalie se trouve en fin de série, dans une plage qui n'a pas été capturée \n",
    "                par une des fenêtres. On peut donc l'ignorer et continuer le traitement. Ce cas est de toute façon très rare\n",
    "                dans nos données.\"\"\"\n",
    "        anom_fen += anom_fen_i\n",
    "        ind_debut += list(range(0, nb_fen * N, N))\n",
    "        serie += [i] * nb_fen\n",
    "        \"\"\"if i < 300:\n",
    "            origine += [\"appr\"] * nb_fen\n",
    "        else:\n",
    "            origine += [\"test\"] * nb_fen\"\"\"\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(data={\"id\" : list(range(len(serie))), \"serie\" : serie, \"ind_debut\" : ind_debut, \"valeurs\" : valeurs, \"anom\" : anom_fen})\n",
    "        \n",
    "    return df.set_index([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80\n",
    "data_fenetres = df_fenetres(liste_propre, N, anom, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_anom = list(data_fenetres[data_fenetres[\"anom\"]][\"serie\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paul-\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie</th>\n",
       "      <th>ind_debut</th>\n",
       "      <th>valeurs</th>\n",
       "      <th>anom</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>energy</th>\n",
       "      <th>average_cross</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43120</th>\n",
       "      <td>40379</td>\n",
       "      <td>480</td>\n",
       "      <td>[1736.0, 1744.0, 1744.0, 1744.0, 1736.0, 1736....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.487393</td>\n",
       "      <td>-0.398950</td>\n",
       "      <td>-1.113270</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.421983</td>\n",
       "      <td>-0.329100</td>\n",
       "      <td>-0.931143</td>\n",
       "      <td>-1.019770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43183</th>\n",
       "      <td>40389</td>\n",
       "      <td>0</td>\n",
       "      <td>[1408.0, 1408.0, 1416.0, 1416.0, 1408.0, 1392....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.120799</td>\n",
       "      <td>-0.125033</td>\n",
       "      <td>-1.080946</td>\n",
       "      <td>0.188032</td>\n",
       "      <td>0.717682</td>\n",
       "      <td>-0.095262</td>\n",
       "      <td>-0.900319</td>\n",
       "      <td>-1.281262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43184</th>\n",
       "      <td>40389</td>\n",
       "      <td>80</td>\n",
       "      <td>[1776.0, 1768.0, 1760.0, 1752.0, 1744.0, 1736....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.764542</td>\n",
       "      <td>0.253233</td>\n",
       "      <td>0.432342</td>\n",
       "      <td>-0.234208</td>\n",
       "      <td>1.838372</td>\n",
       "      <td>1.650946</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>-1.019770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43185</th>\n",
       "      <td>40389</td>\n",
       "      <td>160</td>\n",
       "      <td>[1712.0, 1720.0, 1728.0, 1736.0, 1736.0, 1736....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.416970</td>\n",
       "      <td>-0.398950</td>\n",
       "      <td>-0.957038</td>\n",
       "      <td>0.681360</td>\n",
       "      <td>-0.508641</td>\n",
       "      <td>-0.680021</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>0.483808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43186</th>\n",
       "      <td>40389</td>\n",
       "      <td>240</td>\n",
       "      <td>[1258.0, 1258.0, 1266.0, 1282.0, 1274.0, 1266....</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.998006</td>\n",
       "      <td>2.548920</td>\n",
       "      <td>1.913711</td>\n",
       "      <td>2.976023</td>\n",
       "      <td>-0.063708</td>\n",
       "      <td>-0.504578</td>\n",
       "      <td>2.166144</td>\n",
       "      <td>-0.366040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43187</th>\n",
       "      <td>40389</td>\n",
       "      <td>320</td>\n",
       "      <td>[2704.0, 2696.0, 2696.0, 2696.0, 2464.0, 2048....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.607430</td>\n",
       "      <td>1.153247</td>\n",
       "      <td>0.557866</td>\n",
       "      <td>0.636229</td>\n",
       "      <td>1.641474</td>\n",
       "      <td>1.076765</td>\n",
       "      <td>0.432229</td>\n",
       "      <td>-1.738873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43188</th>\n",
       "      <td>40389</td>\n",
       "      <td>400</td>\n",
       "      <td>[1728.0, 1720.0, 1720.0, 1720.0, 1720.0, 1712....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.592134</td>\n",
       "      <td>-0.411994</td>\n",
       "      <td>-0.654273</td>\n",
       "      <td>0.266551</td>\n",
       "      <td>-0.477614</td>\n",
       "      <td>-0.667638</td>\n",
       "      <td>-0.581345</td>\n",
       "      <td>0.353062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43251</th>\n",
       "      <td>40396</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1400.0, 1408.0, 1408.0, 1424.0, 1424....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.120799</td>\n",
       "      <td>-0.933741</td>\n",
       "      <td>-1.426810</td>\n",
       "      <td>-0.605041</td>\n",
       "      <td>-0.471577</td>\n",
       "      <td>-0.477658</td>\n",
       "      <td>-1.171955</td>\n",
       "      <td>0.810673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43252</th>\n",
       "      <td>40396</td>\n",
       "      <td>80</td>\n",
       "      <td>[1400.0, 1392.0, 1392.0, 1400.0, 1400.0, 1400....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.068428</td>\n",
       "      <td>-0.151120</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>-0.046701</td>\n",
       "      <td>-1.701466</td>\n",
       "      <td>0.046633</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>2.444997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43253</th>\n",
       "      <td>40396</td>\n",
       "      <td>160</td>\n",
       "      <td>[1736.0, 1744.0, 1744.0, 1744.0, 1744.0, 1744....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.078766</td>\n",
       "      <td>-0.281557</td>\n",
       "      <td>0.376853</td>\n",
       "      <td>-0.575899</td>\n",
       "      <td>1.797579</td>\n",
       "      <td>2.034956</td>\n",
       "      <td>0.207817</td>\n",
       "      <td>0.026197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43254</th>\n",
       "      <td>40396</td>\n",
       "      <td>240</td>\n",
       "      <td>[1760.0, 1720.0, 1720.0, 1984.0, 2352.0, 2616....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.594338</td>\n",
       "      <td>1.466295</td>\n",
       "      <td>1.977415</td>\n",
       "      <td>2.065081</td>\n",
       "      <td>0.019807</td>\n",
       "      <td>-0.562368</td>\n",
       "      <td>1.987342</td>\n",
       "      <td>-0.431413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43255</th>\n",
       "      <td>40396</td>\n",
       "      <td>320</td>\n",
       "      <td>[1718.0, 1702.0, 1686.0, 1670.0, 1702.0, 1718....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>2.653269</td>\n",
       "      <td>1.736739</td>\n",
       "      <td>2.885498</td>\n",
       "      <td>0.476622</td>\n",
       "      <td>-0.300171</td>\n",
       "      <td>1.966124</td>\n",
       "      <td>-1.085143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43256</th>\n",
       "      <td>40396</td>\n",
       "      <td>400</td>\n",
       "      <td>[1712.0, 1704.0, 1696.0, 1688.0, 1688.0, 1680....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.435022</td>\n",
       "      <td>-0.438081</td>\n",
       "      <td>-0.064365</td>\n",
       "      <td>-0.212456</td>\n",
       "      <td>-2.084516</td>\n",
       "      <td>0.465950</td>\n",
       "      <td>-0.148749</td>\n",
       "      <td>1.595149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43257</th>\n",
       "      <td>40396</td>\n",
       "      <td>480</td>\n",
       "      <td>[1336.0, 1352.0, 1368.0, 1376.0, 1376.0, 1392....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.435022</td>\n",
       "      <td>1.792387</td>\n",
       "      <td>-0.687674</td>\n",
       "      <td>1.629989</td>\n",
       "      <td>1.109370</td>\n",
       "      <td>0.360399</td>\n",
       "      <td>-0.423539</td>\n",
       "      <td>-1.477381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43269</th>\n",
       "      <td>40399</td>\n",
       "      <td>0</td>\n",
       "      <td>[1456.0, 1456.0, 1456.0, 1456.0, 1456.0, 1448....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.963687</td>\n",
       "      <td>-0.881566</td>\n",
       "      <td>-1.282969</td>\n",
       "      <td>-0.594108</td>\n",
       "      <td>-0.328980</td>\n",
       "      <td>-0.475689</td>\n",
       "      <td>-1.072651</td>\n",
       "      <td>-0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43270</th>\n",
       "      <td>40399</td>\n",
       "      <td>80</td>\n",
       "      <td>[1408.0, 1416.0, 1424.0, 1424.0, 1416.0, 1408....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.416970</td>\n",
       "      <td>-0.516343</td>\n",
       "      <td>-1.861698</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>0.553870</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>-1.443907</td>\n",
       "      <td>-0.496786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43271</th>\n",
       "      <td>40399</td>\n",
       "      <td>160</td>\n",
       "      <td>[1688.0, 1672.0, 1664.0, 1656.0, 1656.0, 1656....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>-0.503299</td>\n",
       "      <td>-0.066520</td>\n",
       "      <td>-0.616600</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>-0.168428</td>\n",
       "      <td>-0.158743</td>\n",
       "      <td>-0.300667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43272</th>\n",
       "      <td>40399</td>\n",
       "      <td>240</td>\n",
       "      <td>[1648.0, 1656.0, 1656.0, 1656.0, 1648.0, 1648....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.083725</td>\n",
       "      <td>1.348902</td>\n",
       "      <td>1.019018</td>\n",
       "      <td>1.682727</td>\n",
       "      <td>0.455503</td>\n",
       "      <td>-0.324375</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>-1.019770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43273</th>\n",
       "      <td>40399</td>\n",
       "      <td>320</td>\n",
       "      <td>[1592.0, 1608.0, 1616.0, 1608.0, 1600.0, 1608....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.125758</td>\n",
       "      <td>-0.581562</td>\n",
       "      <td>-0.463563</td>\n",
       "      <td>-0.487636</td>\n",
       "      <td>-0.394291</td>\n",
       "      <td>-0.585344</td>\n",
       "      <td>-0.470597</td>\n",
       "      <td>0.287689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43274</th>\n",
       "      <td>40399</td>\n",
       "      <td>400</td>\n",
       "      <td>[1536.0, 1536.0, 1544.0, 1544.0, 1544.0, 1544....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.178128</td>\n",
       "      <td>-0.698955</td>\n",
       "      <td>-0.682826</td>\n",
       "      <td>-0.617431</td>\n",
       "      <td>-0.166248</td>\n",
       "      <td>-0.284775</td>\n",
       "      <td>-0.638512</td>\n",
       "      <td>-1.019770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43275</th>\n",
       "      <td>40399</td>\n",
       "      <td>480</td>\n",
       "      <td>[1544.0, 1544.0, 1544.0, 1536.0, 1544.0, 1552....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.539763</td>\n",
       "      <td>-0.698955</td>\n",
       "      <td>-0.942493</td>\n",
       "      <td>-0.222924</td>\n",
       "      <td>-1.153411</td>\n",
       "      <td>-0.493838</td>\n",
       "      <td>-0.822513</td>\n",
       "      <td>1.660522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43354</th>\n",
       "      <td>40407</td>\n",
       "      <td>0</td>\n",
       "      <td>[1464.0, 1464.0, 1456.0, 1456.0, 1456.0, 1456....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.806575</td>\n",
       "      <td>-0.542431</td>\n",
       "      <td>-0.816430</td>\n",
       "      <td>-0.163175</td>\n",
       "      <td>-0.193035</td>\n",
       "      <td>-0.630376</td>\n",
       "      <td>-0.727797</td>\n",
       "      <td>-0.104549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43355</th>\n",
       "      <td>40407</td>\n",
       "      <td>80</td>\n",
       "      <td>[1640.0, 1640.0, 1648.0, 1640.0, 1648.0, 1648....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>0.983679</td>\n",
       "      <td>0.547630</td>\n",
       "      <td>0.786702</td>\n",
       "      <td>0.845738</td>\n",
       "      <td>0.030390</td>\n",
       "      <td>0.440617</td>\n",
       "      <td>-1.346635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43356</th>\n",
       "      <td>40407</td>\n",
       "      <td>160</td>\n",
       "      <td>[2352.0, 2344.0, 2328.0, 2360.0, 2424.0, 2472....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1.229660</td>\n",
       "      <td>1.525179</td>\n",
       "      <td>-0.075189</td>\n",
       "      <td>-0.608797</td>\n",
       "      <td>1.161172</td>\n",
       "      <td>-0.366040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43357</th>\n",
       "      <td>40407</td>\n",
       "      <td>240</td>\n",
       "      <td>[1616.0, 1616.0, 1616.0, 1624.0, 1616.0, 1624....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.397948</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.492680</td>\n",
       "      <td>0.358178</td>\n",
       "      <td>0.870821</td>\n",
       "      <td>0.336250</td>\n",
       "      <td>0.349354</td>\n",
       "      <td>0.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43358</th>\n",
       "      <td>40407</td>\n",
       "      <td>320</td>\n",
       "      <td>[1792.0, 1784.0, 1784.0, 1720.0, 1624.0, 1552....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.021017</td>\n",
       "      <td>-0.333732</td>\n",
       "      <td>-0.030560</td>\n",
       "      <td>-0.407364</td>\n",
       "      <td>-0.551912</td>\n",
       "      <td>-0.250286</td>\n",
       "      <td>-0.127118</td>\n",
       "      <td>1.072165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43359</th>\n",
       "      <td>40407</td>\n",
       "      <td>400</td>\n",
       "      <td>[1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1624....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.345577</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>0.452275</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.633650</td>\n",
       "      <td>-0.164796</td>\n",
       "      <td>0.378228</td>\n",
       "      <td>-1.150516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43360</th>\n",
       "      <td>40407</td>\n",
       "      <td>480</td>\n",
       "      <td>[2392.0, 2456.0, 2520.0, 2528.0, 2520.0, 2328....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.282869</td>\n",
       "      <td>0.866286</td>\n",
       "      <td>-0.111235</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>1.205838</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>-0.116308</td>\n",
       "      <td>-1.412008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43361</th>\n",
       "      <td>40407</td>\n",
       "      <td>560</td>\n",
       "      <td>[1616.0, 1624.0, 1632.0, 1624.0, 1616.0, 1616....</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.282869</td>\n",
       "      <td>2.209784</td>\n",
       "      <td>1.022250</td>\n",
       "      <td>2.624046</td>\n",
       "      <td>0.596466</td>\n",
       "      <td>-0.204381</td>\n",
       "      <td>1.222331</td>\n",
       "      <td>-1.085143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43362</th>\n",
       "      <td>40407</td>\n",
       "      <td>640</td>\n",
       "      <td>[3320.0, 3304.0, 3288.0, 2976.0, 2328.0, 1784....</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.701834</td>\n",
       "      <td>2.157610</td>\n",
       "      <td>-0.172111</td>\n",
       "      <td>1.454792</td>\n",
       "      <td>1.835552</td>\n",
       "      <td>1.434521</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-1.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43399</th>\n",
       "      <td>40413</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1400.0, 1400.0, 1400.0, 1384.0, 1384....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.225540</td>\n",
       "      <td>-0.620693</td>\n",
       "      <td>-1.374014</td>\n",
       "      <td>-0.288726</td>\n",
       "      <td>0.874061</td>\n",
       "      <td>0.068551</td>\n",
       "      <td>-1.130135</td>\n",
       "      <td>-1.412008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43400</th>\n",
       "      <td>40413</td>\n",
       "      <td>80</td>\n",
       "      <td>[1608.0, 1600.0, 1584.0, 1568.0, 1568.0, 1568....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>1.388033</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>1.682717</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>-0.336885</td>\n",
       "      <td>0.882298</td>\n",
       "      <td>-0.889024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43401</th>\n",
       "      <td>40413</td>\n",
       "      <td>160</td>\n",
       "      <td>[2552.0, 2536.0, 2528.0, 2520.0, 2504.0, 2504....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.188466</td>\n",
       "      <td>0.905417</td>\n",
       "      <td>2.359913</td>\n",
       "      <td>1.578404</td>\n",
       "      <td>-0.600537</td>\n",
       "      <td>-0.656877</td>\n",
       "      <td>2.272125</td>\n",
       "      <td>0.810673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43402</th>\n",
       "      <td>40413</td>\n",
       "      <td>240</td>\n",
       "      <td>[2168.0, 2160.0, 2152.0, 2136.0, 2136.0, 2128....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.230499</td>\n",
       "      <td>2.783706</td>\n",
       "      <td>4.543379</td>\n",
       "      <td>3.746129</td>\n",
       "      <td>-0.342864</td>\n",
       "      <td>-0.594395</td>\n",
       "      <td>5.326681</td>\n",
       "      <td>0.679927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>40413</td>\n",
       "      <td>320</td>\n",
       "      <td>[1640.0, 1640.0, 1640.0, 1640.0, 1640.0, 1640....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>-0.451125</td>\n",
       "      <td>0.133887</td>\n",
       "      <td>-0.537662</td>\n",
       "      <td>-1.421691</td>\n",
       "      <td>-0.249301</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>1.922013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>40413</td>\n",
       "      <td>400</td>\n",
       "      <td>[1674.0, 1682.0, 1682.0, 1698.0, 1698.0, 1698....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568152</td>\n",
       "      <td>-0.451125</td>\n",
       "      <td>0.095502</td>\n",
       "      <td>-0.550531</td>\n",
       "      <td>-0.822857</td>\n",
       "      <td>-0.494924</td>\n",
       "      <td>-0.026508</td>\n",
       "      <td>0.941419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>40413</td>\n",
       "      <td>480</td>\n",
       "      <td>[1712.0, 1712.0, 1704.0, 1704.0, 1712.0, 1720....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.644504</td>\n",
       "      <td>-0.438081</td>\n",
       "      <td>-0.004028</td>\n",
       "      <td>-0.052878</td>\n",
       "      <td>-2.099952</td>\n",
       "      <td>0.328477</td>\n",
       "      <td>-0.092911</td>\n",
       "      <td>2.379624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>40413</td>\n",
       "      <td>560</td>\n",
       "      <td>[1352.0, 1360.0, 1368.0, 1384.0, 1376.0, 1368....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.330281</td>\n",
       "      <td>-0.594605</td>\n",
       "      <td>-1.484992</td>\n",
       "      <td>-0.491885</td>\n",
       "      <td>3.361572</td>\n",
       "      <td>6.076557</td>\n",
       "      <td>-1.210523</td>\n",
       "      <td>-0.562159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>40414</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1400.0, 1392.0, 1392.0, 1392.0, 1400....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.225540</td>\n",
       "      <td>-0.881566</td>\n",
       "      <td>-1.498999</td>\n",
       "      <td>-0.595442</td>\n",
       "      <td>0.613978</td>\n",
       "      <td>1.038557</td>\n",
       "      <td>-1.221014</td>\n",
       "      <td>-0.496786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>40414</td>\n",
       "      <td>80</td>\n",
       "      <td>[1512.0, 1544.0, 1560.0, 1584.0, 1592.0, 1600....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.282869</td>\n",
       "      <td>-0.085902</td>\n",
       "      <td>0.631672</td>\n",
       "      <td>-0.182666</td>\n",
       "      <td>-1.541988</td>\n",
       "      <td>-0.081887</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>2.052759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>40414</td>\n",
       "      <td>160</td>\n",
       "      <td>[1800.0, 1816.0, 1808.0, 1816.0, 1808.0, 1800....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445360</td>\n",
       "      <td>-0.294601</td>\n",
       "      <td>0.676386</td>\n",
       "      <td>-0.611321</td>\n",
       "      <td>-0.412220</td>\n",
       "      <td>-0.426088</td>\n",
       "      <td>0.465158</td>\n",
       "      <td>0.353062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43410</th>\n",
       "      <td>40414</td>\n",
       "      <td>240</td>\n",
       "      <td>[1792.0, 1792.0, 1792.0, 1800.0, 1800.0, 1800....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445360</td>\n",
       "      <td>-0.294601</td>\n",
       "      <td>0.666689</td>\n",
       "      <td>-0.615905</td>\n",
       "      <td>-0.450645</td>\n",
       "      <td>-0.409777</td>\n",
       "      <td>0.456677</td>\n",
       "      <td>0.026197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43411</th>\n",
       "      <td>40414</td>\n",
       "      <td>320</td>\n",
       "      <td>[1784.0, 1784.0, 1784.0, 1792.0, 1800.0, 1792....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445360</td>\n",
       "      <td>-0.307644</td>\n",
       "      <td>0.638137</td>\n",
       "      <td>-0.614480</td>\n",
       "      <td>-0.413046</td>\n",
       "      <td>-0.494699</td>\n",
       "      <td>0.431809</td>\n",
       "      <td>0.679927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43412</th>\n",
       "      <td>40414</td>\n",
       "      <td>400</td>\n",
       "      <td>[1790.0, 1782.0, 1774.0, 1750.0, 1742.0, 1734....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>-0.284818</td>\n",
       "      <td>0.330657</td>\n",
       "      <td>-0.319275</td>\n",
       "      <td>-0.823914</td>\n",
       "      <td>-0.593926</td>\n",
       "      <td>0.173354</td>\n",
       "      <td>1.399030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43473</th>\n",
       "      <td>40421</td>\n",
       "      <td>0</td>\n",
       "      <td>[1416.0, 1400.0, 1400.0, 1408.0, 1408.0, 1408....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.120799</td>\n",
       "      <td>-0.607649</td>\n",
       "      <td>-1.370243</td>\n",
       "      <td>-0.393837</td>\n",
       "      <td>1.522565</td>\n",
       "      <td>0.960514</td>\n",
       "      <td>-1.130329</td>\n",
       "      <td>-1.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43474</th>\n",
       "      <td>40421</td>\n",
       "      <td>80</td>\n",
       "      <td>[1632.0, 1632.0, 1632.0, 1632.0, 1616.0, 1616....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.188466</td>\n",
       "      <td>0.644544</td>\n",
       "      <td>0.126883</td>\n",
       "      <td>0.295146</td>\n",
       "      <td>1.363293</td>\n",
       "      <td>0.761506</td>\n",
       "      <td>0.036817</td>\n",
       "      <td>-0.889024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43475</th>\n",
       "      <td>40421</td>\n",
       "      <td>160</td>\n",
       "      <td>[2048.0, 2000.0, 1920.0, 1848.0, 1808.0, 1792....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869283</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>0.371466</td>\n",
       "      <td>-0.348687</td>\n",
       "      <td>1.889410</td>\n",
       "      <td>1.897639</td>\n",
       "      <td>0.206996</td>\n",
       "      <td>-1.281262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43476</th>\n",
       "      <td>40421</td>\n",
       "      <td>240</td>\n",
       "      <td>[1728.0, 1736.0, 1744.0, 1744.0, 1736.0, 1728....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.207488</td>\n",
       "      <td>3.083710</td>\n",
       "      <td>0.784671</td>\n",
       "      <td>2.729117</td>\n",
       "      <td>0.587033</td>\n",
       "      <td>-0.043973</td>\n",
       "      <td>1.039233</td>\n",
       "      <td>-1.215889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43477</th>\n",
       "      <td>40421</td>\n",
       "      <td>320</td>\n",
       "      <td>[1186.0, 1202.0, 1202.0, 1234.0, 1242.0, 1258....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.416970</td>\n",
       "      <td>-0.425037</td>\n",
       "      <td>-0.799326</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>-0.664939</td>\n",
       "      <td>-0.669484</td>\n",
       "      <td>-0.655889</td>\n",
       "      <td>0.810673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43478</th>\n",
       "      <td>40421</td>\n",
       "      <td>400</td>\n",
       "      <td>[1728.0, 1728.0, 1728.0, 1728.0, 1728.0, 1728....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.592134</td>\n",
       "      <td>-0.425037</td>\n",
       "      <td>-1.207547</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.540843</td>\n",
       "      <td>-0.217851</td>\n",
       "      <td>-1.001184</td>\n",
       "      <td>-1.085143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       serie  ind_debut                                            valeurs  \\\n",
       "id                                                                           \n",
       "43120  40379        480  [1736.0, 1744.0, 1744.0, 1744.0, 1736.0, 1736....   \n",
       "43183  40389          0  [1408.0, 1408.0, 1416.0, 1416.0, 1408.0, 1392....   \n",
       "43184  40389         80  [1776.0, 1768.0, 1760.0, 1752.0, 1744.0, 1736....   \n",
       "43185  40389        160  [1712.0, 1720.0, 1728.0, 1736.0, 1736.0, 1736....   \n",
       "43186  40389        240  [1258.0, 1258.0, 1266.0, 1282.0, 1274.0, 1266....   \n",
       "43187  40389        320  [2704.0, 2696.0, 2696.0, 2696.0, 2464.0, 2048....   \n",
       "43188  40389        400  [1728.0, 1720.0, 1720.0, 1720.0, 1720.0, 1712....   \n",
       "43251  40396          0  [1400.0, 1400.0, 1408.0, 1408.0, 1424.0, 1424....   \n",
       "43252  40396         80  [1400.0, 1392.0, 1392.0, 1400.0, 1400.0, 1400....   \n",
       "43253  40396        160  [1736.0, 1744.0, 1744.0, 1744.0, 1744.0, 1744....   \n",
       "43254  40396        240  [1760.0, 1720.0, 1720.0, 1984.0, 2352.0, 2616....   \n",
       "43255  40396        320  [1718.0, 1702.0, 1686.0, 1670.0, 1702.0, 1718....   \n",
       "43256  40396        400  [1712.0, 1704.0, 1696.0, 1688.0, 1688.0, 1680....   \n",
       "43257  40396        480  [1336.0, 1352.0, 1368.0, 1376.0, 1376.0, 1392....   \n",
       "43269  40399          0  [1456.0, 1456.0, 1456.0, 1456.0, 1456.0, 1448....   \n",
       "43270  40399         80  [1408.0, 1416.0, 1424.0, 1424.0, 1416.0, 1408....   \n",
       "43271  40399        160  [1688.0, 1672.0, 1664.0, 1656.0, 1656.0, 1656....   \n",
       "43272  40399        240  [1648.0, 1656.0, 1656.0, 1656.0, 1648.0, 1648....   \n",
       "43273  40399        320  [1592.0, 1608.0, 1616.0, 1608.0, 1600.0, 1608....   \n",
       "43274  40399        400  [1536.0, 1536.0, 1544.0, 1544.0, 1544.0, 1544....   \n",
       "43275  40399        480  [1544.0, 1544.0, 1544.0, 1536.0, 1544.0, 1552....   \n",
       "43354  40407          0  [1464.0, 1464.0, 1456.0, 1456.0, 1456.0, 1456....   \n",
       "43355  40407         80  [1640.0, 1640.0, 1648.0, 1640.0, 1648.0, 1648....   \n",
       "43356  40407        160  [2352.0, 2344.0, 2328.0, 2360.0, 2424.0, 2472....   \n",
       "43357  40407        240  [1616.0, 1616.0, 1616.0, 1624.0, 1616.0, 1624....   \n",
       "43358  40407        320  [1792.0, 1784.0, 1784.0, 1720.0, 1624.0, 1552....   \n",
       "43359  40407        400  [1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1624....   \n",
       "43360  40407        480  [2392.0, 2456.0, 2520.0, 2528.0, 2520.0, 2328....   \n",
       "43361  40407        560  [1616.0, 1624.0, 1632.0, 1624.0, 1616.0, 1616....   \n",
       "43362  40407        640  [3320.0, 3304.0, 3288.0, 2976.0, 2328.0, 1784....   \n",
       "43399  40413          0  [1400.0, 1400.0, 1400.0, 1400.0, 1384.0, 1384....   \n",
       "43400  40413         80  [1608.0, 1600.0, 1584.0, 1568.0, 1568.0, 1568....   \n",
       "43401  40413        160  [2552.0, 2536.0, 2528.0, 2520.0, 2504.0, 2504....   \n",
       "43402  40413        240  [2168.0, 2160.0, 2152.0, 2136.0, 2136.0, 2128....   \n",
       "43403  40413        320  [1640.0, 1640.0, 1640.0, 1640.0, 1640.0, 1640....   \n",
       "43404  40413        400  [1674.0, 1682.0, 1682.0, 1698.0, 1698.0, 1698....   \n",
       "43405  40413        480  [1712.0, 1712.0, 1704.0, 1704.0, 1712.0, 1720....   \n",
       "43406  40413        560  [1352.0, 1360.0, 1368.0, 1384.0, 1376.0, 1368....   \n",
       "43407  40414          0  [1400.0, 1400.0, 1392.0, 1392.0, 1392.0, 1400....   \n",
       "43408  40414         80  [1512.0, 1544.0, 1560.0, 1584.0, 1592.0, 1600....   \n",
       "43409  40414        160  [1800.0, 1816.0, 1808.0, 1816.0, 1808.0, 1800....   \n",
       "43410  40414        240  [1792.0, 1792.0, 1792.0, 1800.0, 1800.0, 1800....   \n",
       "43411  40414        320  [1784.0, 1784.0, 1784.0, 1792.0, 1800.0, 1792....   \n",
       "43412  40414        400  [1790.0, 1782.0, 1774.0, 1750.0, 1742.0, 1734....   \n",
       "43473  40421          0  [1416.0, 1400.0, 1400.0, 1408.0, 1408.0, 1408....   \n",
       "43474  40421         80  [1632.0, 1632.0, 1632.0, 1632.0, 1616.0, 1616....   \n",
       "43475  40421        160  [2048.0, 2000.0, 1920.0, 1848.0, 1808.0, 1792....   \n",
       "43476  40421        240  [1728.0, 1736.0, 1744.0, 1744.0, 1736.0, 1728....   \n",
       "43477  40421        320  [1186.0, 1202.0, 1202.0, 1234.0, 1242.0, 1258....   \n",
       "43478  40421        400  [1728.0, 1728.0, 1728.0, 1728.0, 1728.0, 1728....   \n",
       "\n",
       "        anom       min       max      mean       std      skew      kurt  \\\n",
       "id                                                                         \n",
       "43120  False -1.487393 -0.398950 -1.113270  0.069942  0.421983 -0.329100   \n",
       "43183  False -1.120799 -0.125033 -1.080946  0.188032  0.717682 -0.095262   \n",
       "43184  False  0.764542  0.253233  0.432342 -0.234208  1.838372  1.650946   \n",
       "43185   True -2.416970 -0.398950 -0.957038  0.681360 -0.508641 -0.680021   \n",
       "43186   True -1.998006  2.548920  1.913711  2.976023 -0.063708 -0.504578   \n",
       "43187  False  0.607430  1.153247  0.557866  0.636229  1.641474  1.076765   \n",
       "43188  False -1.592134 -0.411994 -0.654273  0.266551 -0.477614 -0.667638   \n",
       "43251  False -1.120799 -0.933741 -1.426810 -0.605041 -0.471577 -0.477658   \n",
       "43252  False -1.068428 -0.151120  0.186143 -0.046701 -1.701466  0.046633   \n",
       "43253  False  1.078766 -0.281557  0.376853 -0.575899  1.797579  2.034956   \n",
       "43254   True  0.594338  1.466295  1.977415  2.065081  0.019807 -0.562368   \n",
       "43255   True  0.031354  2.653269  1.736739  2.885498  0.476622 -0.300171   \n",
       "43256  False -1.435022 -0.438081 -0.064365 -0.212456 -2.084516  0.465950   \n",
       "43257  False -1.435022  1.792387 -0.687674  1.629989  1.109370  0.360399   \n",
       "43269  False -0.963687 -0.881566 -1.282969 -0.594108 -0.328980 -0.475689   \n",
       "43270   True -2.416970 -0.516343 -1.861698 -0.023196  0.553870 -0.034111   \n",
       "43271  False  0.555060 -0.503299 -0.066520 -0.616600 -0.042136 -0.168428   \n",
       "43272  False  0.083725  1.348902  1.019018  1.682727  0.455503 -0.324375   \n",
       "43273  False -0.125758 -0.581562 -0.463563 -0.487636 -0.394291 -0.585344   \n",
       "43274  False -0.178128 -0.698955 -0.682826 -0.617431 -0.166248 -0.284775   \n",
       "43275  False -1.539763 -0.698955 -0.942493 -0.222924 -1.153411 -0.493838   \n",
       "43354  False -0.806575 -0.542431 -0.816430 -0.163175 -0.193035 -0.630376   \n",
       "43355  False  0.555060  0.983679  0.547630  0.786702  0.845738  0.030390   \n",
       "43356  False  0.031354  0.801068  1.229660  1.525179 -0.075189 -0.608797   \n",
       "43357  False  0.397948  0.735849  0.492680  0.358178  0.870821  0.336250   \n",
       "43358  False -0.021017 -0.333732 -0.030560 -0.407364 -0.551912 -0.250286   \n",
       "43359  False  0.345577  1.009766  0.452275  0.939156  0.633650 -0.164796   \n",
       "43360  False -0.282869  0.866286 -0.111235  0.712036  1.205838  0.484764   \n",
       "43361   True -0.282869  2.209784  1.022250  2.624046  0.596466 -0.204381   \n",
       "43362   True -0.701834  2.157610 -0.172111  1.454792  1.835552  1.434521   \n",
       "43399  False -1.225540 -0.620693 -1.374014 -0.288726  0.874061  0.068551   \n",
       "43400  False  0.031354  1.388033  0.889723  1.682717  0.416382 -0.336885   \n",
       "43401  False  0.188466  0.905417  2.359913  1.578404 -0.600537 -0.656877   \n",
       "43402  False -0.230499  2.783706  4.543379  3.746129 -0.342864 -0.594395   \n",
       "43403  False  0.555060 -0.451125  0.133887 -0.537662 -1.421691 -0.249301   \n",
       "43404   True  0.568152 -0.451125  0.095502 -0.550531 -0.822857 -0.494924   \n",
       "43405  False -1.644504 -0.438081 -0.004028 -0.052878 -2.099952  0.328477   \n",
       "43406  False -1.330281 -0.594605 -1.484992 -0.491885  3.361572  6.076557   \n",
       "43407  False -1.225540 -0.881566 -1.498999 -0.595442  0.613978  1.038557   \n",
       "43408  False -0.282869 -0.085902  0.631672 -0.182666 -1.541988 -0.081887   \n",
       "43409  False  1.445360 -0.294601  0.676386 -0.611321 -0.412220 -0.426088   \n",
       "43410  False  1.445360 -0.294601  0.666689 -0.615905 -0.450645 -0.409777   \n",
       "43411  False  1.445360 -0.307644  0.638137 -0.614480 -0.413046 -0.494699   \n",
       "43412   True  0.555060 -0.284818  0.330657 -0.319275 -0.823914 -0.593926   \n",
       "43473  False -1.120799 -0.607649 -1.370243 -0.393837  1.522565  0.960514   \n",
       "43474  False  0.188466  0.644544  0.126883  0.295146  1.363293  0.761506   \n",
       "43475  False  0.869283  0.083666  0.371466 -0.348687  1.889410  1.897639   \n",
       "43476   True -2.207488  3.083710  0.784671  2.729117  0.587033 -0.043973   \n",
       "43477   True -2.416970 -0.425037 -0.799326  0.631567 -0.664939 -0.669484   \n",
       "43478  False -1.592134 -0.425037 -1.207547  0.012911  0.540843 -0.217851   \n",
       "\n",
       "         energy  average_cross  \n",
       "id                              \n",
       "43120 -0.931143      -1.019770  \n",
       "43183 -0.900319      -1.281262  \n",
       "43184  0.262166      -1.019770  \n",
       "43185 -0.766028       0.483808  \n",
       "43186  2.166144      -0.366040  \n",
       "43187  0.432229      -1.738873  \n",
       "43188 -0.581345       0.353062  \n",
       "43251 -1.171955       0.810673  \n",
       "43252  0.063436       2.444997  \n",
       "43253  0.207817       0.026197  \n",
       "43254  1.987342      -0.431413  \n",
       "43255  1.966124      -1.085143  \n",
       "43256 -0.148749       1.595149  \n",
       "43257 -0.423539      -1.477381  \n",
       "43269 -1.072651      -0.235294  \n",
       "43270 -1.443907      -0.496786  \n",
       "43271 -0.158743      -0.300667  \n",
       "43272  0.998458      -1.019770  \n",
       "43273 -0.470597       0.287689  \n",
       "43274 -0.638512      -1.019770  \n",
       "43275 -0.822513       1.660522  \n",
       "43354 -0.727797      -0.104549  \n",
       "43355  0.440617      -1.346635  \n",
       "43356  1.161172      -0.366040  \n",
       "43357  0.349354       0.745300  \n",
       "43358 -0.127118       1.072165  \n",
       "43359  0.378228      -1.150516  \n",
       "43360 -0.116308      -1.412008  \n",
       "43361  1.222331      -1.085143  \n",
       "43362 -0.056955      -1.673500  \n",
       "43399 -1.130135      -1.412008  \n",
       "43400  0.882298      -0.889024  \n",
       "43401  2.272125       0.810673  \n",
       "43402  5.326681       0.679927  \n",
       "43403  0.005191       1.922013  \n",
       "43404 -0.026508       0.941419  \n",
       "43405 -0.092911       2.379624  \n",
       "43406 -1.210523      -0.562159  \n",
       "43407 -1.221014      -0.496786  \n",
       "43408  0.435584       2.052759  \n",
       "43409  0.465158       0.353062  \n",
       "43410  0.456677       0.026197  \n",
       "43411  0.431809       0.679927  \n",
       "43412  0.173354       1.399030  \n",
       "43473 -1.130329      -1.673500  \n",
       "43474  0.036817      -0.889024  \n",
       "43475  0.206996      -1.281262  \n",
       "43476  1.039233      -1.215889  \n",
       "43477 -0.655889       0.810673  \n",
       "43478 -1.001184      -1.085143  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toutes les fenetres des séries contenant une anomalie\n",
    "data_ajout_anom = data_fenetres.loc[data_fenetres[\"serie\"].isin(ind_anom)] \n",
    "# On met un indice d'une grande puisance de 10 pour identifier plus facilement les fenetres ajoutees\n",
    "offset = 10 ** (int(np.log10(data_fenetres.index.values[-1])) + 1)\n",
    "\n",
    "df_supervise = data_fenetres\n",
    "for i in range(1,5):\n",
    "    data_ajout_anom.index += offset\n",
    "    data_ajout_anom.serie += offset\n",
    "    df_supervise = pd.concat([df_supervise, data_ajout_anom])\n",
    "    \n",
    "# df_supervise contient les données d'apprentissage + les données de tests + les séries anormales recopiées 4 fois\n",
    "# les séries recopiées ont pour indice leur indice de départ + k*offset pour k=1,..,4\n",
    "df_supervise.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anom_type(Type):\n",
    "    for num in df_supervise.index.values:\n",
    "        TS = df_supervise.loc[num]\n",
    "        loc = TS[\"loc\"]\n",
    "        serie = TS[\"valeurs\"]\n",
    "\n",
    "        if TS[\"type\"] == Type: \n",
    "            fig, ax = plt.subplots(figsize=(12, 7))\n",
    "            plt.title(\"Série numéro \" + str(num) + \", type \" + str(Type), size=20, color='r', fontweight='bold')\n",
    "\n",
    "            ax.plot(range(loc), serie[: loc], 'b')\n",
    "            ax.plot(range(loc - 1, loc + 56), serie[loc - 1 : loc + 56], 'r')\n",
    "            ax.plot(range(loc + 55, len(serie)), serie[loc + 55 :], 'b')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marche plus avec le nouveau DataFrame, à adapter si besoin.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for T in range(1, 5):\n",
    "        plot_anom_type(T)\n",
    "except KeyError:\n",
    "    print(\"Marche plus avec le nouveau DataFrame, à adapter si besoin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes de Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Calcul des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervise[\"min\"] = list(map(min, df_supervise.valeurs))\n",
    "df_supervise[\"max\"] = list(map(max, df_supervise.valeurs))\n",
    "df_supervise[\"mean\"] = list(map(np.mean, df_supervise.valeurs))\n",
    "df_supervise[\"std\"] = list(map(np.std, df_supervise.valeurs))\n",
    "df_supervise[\"skew\"] = list(map(sps.skew, df_supervise.valeurs))\n",
    "df_supervise[\"kurt\"] = list(map(sps.kurtosis, df_supervise.valeurs))\n",
    "df_supervise[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), df_supervise.valeurs))\n",
    "df_supervise[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), df_supervise.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    df_supervise[col] = scaler.fit_transform(df_supervise[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4130, 12)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_test = df_supervise.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_supervise[names_features], df_supervise[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025417574437182067\n"
     ]
    }
   ],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(X_train, Y_train)\n",
    "print(1 - rfFit.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfFit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur score = 0.002179, Meilleur paramètre = {'max_features': 2}\n"
     ]
    }
   ],
   "source": [
    "param = [{\"max_features\" : list(range(2, len(names_features) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_,rfOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfOpt.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prévision\n",
    "y_chap = rfOpt.predict(X_test)\n",
    "# matrice de confusion\n",
    "# Options pour normalize : all, index, column\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 5))\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[0], annot_kws={\"size\": 16}) # font size\n",
    "ax[0].set_title(\"Matrice de confusion normalisée \\n selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1].set_title(\"Matrice de confusion normalisée \\n selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire : 1,2% d'erreurs, c'est très faible mais si on regarde la matrice de confusion on voit que la prévision n'est en fait pas si efficace. En effet on observe beaucoup de faux négatifs, envion un tiers. On a pas contre quasi aucun faux positif.\n",
    "\n",
    "On teste la même chose mais sans dupliquer les anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fenetres[\"min\"] = list(map(min, data_fenetres.valeurs))\n",
    "data_fenetres[\"max\"] = list(map(max, data_fenetres.valeurs))\n",
    "data_fenetres[\"mean\"] = list(map(np.mean, data_fenetres.valeurs))\n",
    "data_fenetres[\"std\"] = list(map(np.std, data_fenetres.valeurs))\n",
    "data_fenetres[\"skew\"] = list(map(sps.skew, data_fenetres.valeurs))\n",
    "data_fenetres[\"kurt\"] = list(map(sps.kurtosis, data_fenetres.valeurs))\n",
    "data_fenetres[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), data_fenetres.valeurs))\n",
    "data_fenetres[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), data_fenetres.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    data_fenetres[col] = scaler.fit_transform(data_fenetres[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3526, 12)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fenetres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taille_test = data_fenetres.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_fenetres[names_features], data_fenetres[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008507018290089374\n"
     ]
    }
   ],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(X_train, Y_train)\n",
    "print(1 - rfFit.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010212765957446801"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfFit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur score = 0.007656, Meilleur paramètre = {'max_features': 2}\n"
     ]
    }
   ],
   "source": [
    "param = [{\"max_features\" : list(range(2, len(names_features) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010212765957446801"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfOpt.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prévision\n",
    "y_chap = rfFit.predict(X_test)\n",
    "# matrice de confusion\n",
    "# Options pour normalize : all, index, column\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 5))\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[0], annot_kws={\"size\": 16}) # font size\n",
    "ax[0].set_title(\"Matrice de confusion normalisée \\n selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1].set_title(\"Matrice de confusion normalisée \\n selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire : Le modèle répond quasi systématiquement Non, et donc se trompe très peu. C'est parfaitement inexploitable, il faut garder la version en dupliquant les anomalies ou trouver une autre idée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4130, 80)\n",
      "(4130, 8)\n"
     ]
    }
   ],
   "source": [
    "from scipy.fftpack import fft\n",
    "fftCoeff =[]\n",
    "for x in df_supervise[\"valeurs\"]:\n",
    "    mx = np.mean(x)\n",
    "    x_centre = x - mx\n",
    "    #Apply fast Fourier transform\n",
    "    coeffsfft = np.abs(fft(x_centre))\n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "    \n",
    "fftCoeff = np.array(fftCoeff)\n",
    "print(fftCoeff.shape)\n",
    "\n",
    "#Coefficients seuillés\n",
    "prop_a_garder = 0.1\n",
    "nb_coeffs = int(fftCoeff.shape[1] * prop_a_garder)\n",
    "somme = np.sum(fftCoeff**2, axis=0)\n",
    "fftCoeff_seuil = np.zeros((0, nb_coeffs))\n",
    "ind_grands = np.argsort(somme)[-nb_coeffs :]\n",
    "fftCoeff_seuil = fftCoeff[:, ind_grands]\n",
    "\n",
    "print(fftCoeff_seuil.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fourier = pd.DataFrame(fftCoeff)\n",
    "df_Fourier_seuil = pd.DataFrame(fftCoeff_seuil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_Fourier.columns :\n",
    "    df_Fourier[col] = scaler.fit_transform(df_Fourier[col].values.reshape(-1, 1))\n",
    "for col in df_Fourier_seuil.columns :\n",
    "    df_Fourier_seuil[col] = scaler.fit_transform(df_Fourier_seuil[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients d'ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4130, 80) (4130, 89)\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "wavelist=['haar', 'db2']\n",
    "\n",
    "wavelist=['haar', 'db2'] \n",
    "\n",
    "Coeff_ond_haar = []\n",
    "Coeff_ond_db2 = []\n",
    "\n",
    "for x in df_supervise[\"valeurs\"]:\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs_haar = pywt.wavedec(x, wavelist[0], level=4) \n",
    "    coeffs_flatten_haar, coeff_slices_haar = pywt.coeffs_to_array(coeffs_haar)\n",
    "    Coeff_ond_haar.append(coeffs_flatten_haar)\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs_db2 = pywt.wavedec(x, wavelist[1], level=4) \n",
    "    coeffs_flatten_db2, coeff_slices_db2 = pywt.coeffs_to_array(coeffs_db2)\n",
    "    Coeff_ond_db2.append(coeffs_flatten_db2)\n",
    "    \n",
    "    \n",
    "Coeff_ond_haar = np.array(Coeff_ond_haar)\n",
    "Coeff_ond_db2 = np.array(Coeff_ond_db2)\n",
    "\n",
    "print(Coeff_ond_haar.shape, Coeff_ond_db2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ond_haar = pd.DataFrame(Coeff_ond_haar)\n",
    "df_ond_db2 = pd.DataFrame(Coeff_ond_db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df_ond_haar.columns :\n",
    "#    df_ond_haar[col] = scaler.fit_transform(df_ond_haar[col].values.reshape(-1, 1))\n",
    "#for col in df_ond_db2.columns :\n",
    "#    df_ond_db2[col] = scaler.fit_transform(df_ond_db2[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130\n"
     ]
    }
   ],
   "source": [
    "# Interactive display\n",
    "from ipywidgets import interact, widgets, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "df_liste = [\"Features\",\n",
    "            \"Ondelettes_haar\",\n",
    "            \"Ondelettes_db2\",\n",
    "            \"Coefficients de Fourier\",\n",
    "            \"Coefficients de Fourier seuillés\"\n",
    "           ]\n",
    "\n",
    "dict_df = {\"Features\" : df_supervise[names_features],\n",
    "           \"Ondelettes_haar\" : df_ond_haar,\n",
    "           \"Ondelettes_db2\" : df_ond_db2,\n",
    "           \"Coefficients de Fourier\" : df_Fourier,\n",
    "           \"Coefficients de Fourier seuillés\" : df_Fourier_seuil\n",
    "          }\n",
    "\n",
    "taille_max = df_supervise.shape[0]\n",
    "print(taille_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie</th>\n",
       "      <th>ind_debut</th>\n",
       "      <th>valeurs</th>\n",
       "      <th>anom</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>energy</th>\n",
       "      <th>average_cross</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1424.0, 1432.0, 1432.0, 1416.0, 1408.0, 1408....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.028339</td>\n",
       "      <td>-0.385591</td>\n",
       "      <td>-0.752975</td>\n",
       "      <td>0.072871</td>\n",
       "      <td>-0.277912</td>\n",
       "      <td>-0.646449</td>\n",
       "      <td>-0.669422</td>\n",
       "      <td>0.157725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>[1696.0, 1704.0, 1704.0, 1712.0, 1704.0, 1696....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.835693</td>\n",
       "      <td>1.810158</td>\n",
       "      <td>0.937659</td>\n",
       "      <td>1.343193</td>\n",
       "      <td>0.937661</td>\n",
       "      <td>0.173286</td>\n",
       "      <td>0.866756</td>\n",
       "      <td>-1.072926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>[1696.0, 1664.0, 1632.0, 1624.0, 1616.0, 1624....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.421463</td>\n",
       "      <td>1.164350</td>\n",
       "      <td>1.960728</td>\n",
       "      <td>0.723111</td>\n",
       "      <td>-0.605105</td>\n",
       "      <td>-0.461779</td>\n",
       "      <td>1.744010</td>\n",
       "      <td>1.064520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>[2056.0, 2056.0, 2056.0, 2048.0, 2008.0, 1808....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317906</td>\n",
       "      <td>0.079391</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>-0.146684</td>\n",
       "      <td>1.517035</td>\n",
       "      <td>0.918398</td>\n",
       "      <td>-0.039608</td>\n",
       "      <td>-1.720636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>[1664.0, 1664.0, 1664.0, 1664.0, 1656.0, 1656....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.576799</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>-0.043555</td>\n",
       "      <td>-0.622430</td>\n",
       "      <td>-0.469716</td>\n",
       "      <td>-0.376161</td>\n",
       "      <td>-0.142609</td>\n",
       "      <td>1.388375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>[1680.0, 1680.0, 1672.0, 1664.0, 1672.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.421463</td>\n",
       "      <td>1.629332</td>\n",
       "      <td>0.520696</td>\n",
       "      <td>0.811596</td>\n",
       "      <td>1.278931</td>\n",
       "      <td>0.771192</td>\n",
       "      <td>0.421346</td>\n",
       "      <td>-1.072926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>[1656.0, 1672.0, 1672.0, 1672.0, 1672.0, 1664....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.473242</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>0.027970</td>\n",
       "      <td>-0.484805</td>\n",
       "      <td>2.149219</td>\n",
       "      <td>2.536853</td>\n",
       "      <td>-0.083170</td>\n",
       "      <td>-0.230902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>[1664.0, 1672.0, 1664.0, 1664.0, 1672.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.753241</td>\n",
       "      <td>2.494715</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>3.107377</td>\n",
       "      <td>0.470043</td>\n",
       "      <td>-0.265795</td>\n",
       "      <td>1.292936</td>\n",
       "      <td>-1.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1384.0, 1384.0, 1392.0, 1400.0, 1400....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.183675</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>-1.312987</td>\n",
       "      <td>-0.073798</td>\n",
       "      <td>1.375516</td>\n",
       "      <td>0.706834</td>\n",
       "      <td>-1.079589</td>\n",
       "      <td>-1.591094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>[1736.0, 1736.0, 1736.0, 1744.0, 1744.0, 1744....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.835693</td>\n",
       "      <td>-0.411423</td>\n",
       "      <td>0.196450</td>\n",
       "      <td>-0.574115</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>-0.392720</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>-0.101360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>[1704.0, 1704.0, 1704.0, 1712.0, 1712.0, 1704....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.525021</td>\n",
       "      <td>1.810158</td>\n",
       "      <td>0.962560</td>\n",
       "      <td>0.935434</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.485903</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>-0.230902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>[1840.0, 1816.0, 1784.0, 1760.0, 1728.0, 1696....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317906</td>\n",
       "      <td>2.120146</td>\n",
       "      <td>1.719133</td>\n",
       "      <td>1.302393</td>\n",
       "      <td>0.479276</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>1.589782</td>\n",
       "      <td>0.546351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>[1672.0, 1672.0, 1672.0, 1672.0, 1672.0, 1680....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.783914</td>\n",
       "      <td>-0.501836</td>\n",
       "      <td>0.064527</td>\n",
       "      <td>-0.640654</td>\n",
       "      <td>-0.678098</td>\n",
       "      <td>-0.458010</td>\n",
       "      <td>-0.054783</td>\n",
       "      <td>0.675893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>[1680.0, 1680.0, 1680.0, 1680.0, 1696.0, 1704....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.649683</td>\n",
       "      <td>0.363547</td>\n",
       "      <td>-0.816552</td>\n",
       "      <td>0.309408</td>\n",
       "      <td>0.094834</td>\n",
       "      <td>-0.245674</td>\n",
       "      <td>-0.699158</td>\n",
       "      <td>0.157725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1416.0, 1424.0, 1424.0, 1424.0, 1424.0, 1416....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.028339</td>\n",
       "      <td>-0.308094</td>\n",
       "      <td>-0.792711</td>\n",
       "      <td>0.152231</td>\n",
       "      <td>-0.148238</td>\n",
       "      <td>-0.612016</td>\n",
       "      <td>-0.693595</td>\n",
       "      <td>-0.101360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[1696.0, 1688.0, 1680.0, 1680.0, 1688.0, 1688....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>0.105224</td>\n",
       "      <td>0.287578</td>\n",
       "      <td>-0.206944</td>\n",
       "      <td>0.916802</td>\n",
       "      <td>0.353261</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>-0.554757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>[1680.0, 1672.0, 1672.0, 1672.0, 1672.0, 1664....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.732135</td>\n",
       "      <td>-0.476004</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>-0.623573</td>\n",
       "      <td>-0.214216</td>\n",
       "      <td>-0.369946</td>\n",
       "      <td>-0.055157</td>\n",
       "      <td>0.481580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>[1664.0, 1672.0, 1680.0, 1688.0, 1680.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.732135</td>\n",
       "      <td>-0.488920</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.627769</td>\n",
       "      <td>-0.121607</td>\n",
       "      <td>-0.351018</td>\n",
       "      <td>-0.080702</td>\n",
       "      <td>0.805435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>[1672.0, 1672.0, 1680.0, 1680.0, 1680.0, 1688....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.732135</td>\n",
       "      <td>-0.501836</td>\n",
       "      <td>0.023731</td>\n",
       "      <td>-0.622130</td>\n",
       "      <td>-0.178157</td>\n",
       "      <td>-0.504242</td>\n",
       "      <td>-0.088017</td>\n",
       "      <td>0.028182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>[1672.0, 1680.0, 1688.0, 1680.0, 1680.0, 1680....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680357</td>\n",
       "      <td>-0.501836</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>-0.620257</td>\n",
       "      <td>-0.434229</td>\n",
       "      <td>-0.513466</td>\n",
       "      <td>-0.102234</td>\n",
       "      <td>-0.101360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>[1656.0, 1664.0, 1664.0, 1672.0, 1672.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>-0.527668</td>\n",
       "      <td>-0.021303</td>\n",
       "      <td>-0.636495</td>\n",
       "      <td>-0.796507</td>\n",
       "      <td>-0.337467</td>\n",
       "      <td>-0.124654</td>\n",
       "      <td>0.546351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>[1672.0, 1664.0, 1664.0, 1664.0, 1672.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680357</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>-0.013885</td>\n",
       "      <td>-0.631961</td>\n",
       "      <td>-0.344989</td>\n",
       "      <td>-0.455776</td>\n",
       "      <td>-0.118626</td>\n",
       "      <td>0.675893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>[1680.0, 1680.0, 1672.0, 1672.0, 1672.0, 1664....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.630546</td>\n",
       "      <td>-0.680619</td>\n",
       "      <td>-0.395817</td>\n",
       "      <td>-0.120339</td>\n",
       "      <td>0.870206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>[1672.0, 1664.0, 1664.0, 1664.0, 1664.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.753241</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>-0.702113</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>-0.733851</td>\n",
       "      <td>-0.643377</td>\n",
       "      <td>-0.624564</td>\n",
       "      <td>0.934977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1392.0, 1384.0, 1376.0, 1384.0, 1392....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.235454</td>\n",
       "      <td>-0.966818</td>\n",
       "      <td>-1.492064</td>\n",
       "      <td>-0.621531</td>\n",
       "      <td>-0.756188</td>\n",
       "      <td>-0.395522</td>\n",
       "      <td>-1.217122</td>\n",
       "      <td>0.999748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>[1360.0, 1392.0, 1480.0, 1632.0, 1720.0, 1768....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.235454</td>\n",
       "      <td>-0.372674</td>\n",
       "      <td>-0.036667</td>\n",
       "      <td>-0.353589</td>\n",
       "      <td>-2.445456</td>\n",
       "      <td>1.522810</td>\n",
       "      <td>-0.132818</td>\n",
       "      <td>1.453146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>[1672.0, 1656.0, 1648.0, 1664.0, 1664.0, 1664....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266127</td>\n",
       "      <td>1.939320</td>\n",
       "      <td>1.078059</td>\n",
       "      <td>1.645343</td>\n",
       "      <td>0.800956</td>\n",
       "      <td>0.066936</td>\n",
       "      <td>1.049266</td>\n",
       "      <td>-0.749070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>[1672.0, 1672.0, 1680.0, 1680.0, 1664.0, 1656....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.627265</td>\n",
       "      <td>-0.623009</td>\n",
       "      <td>-0.429534</td>\n",
       "      <td>-0.120327</td>\n",
       "      <td>0.934977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>[1672.0, 1656.0, 1656.0, 1664.0, 1672.0, 1672....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>-0.514752</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>-0.629536</td>\n",
       "      <td>-0.970776</td>\n",
       "      <td>-0.333396</td>\n",
       "      <td>-0.106577</td>\n",
       "      <td>1.712230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>[1680.0, 1672.0, 1672.0, 1672.0, 1680.0, 1680....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.473242</td>\n",
       "      <td>1.861823</td>\n",
       "      <td>0.363871</td>\n",
       "      <td>0.865705</td>\n",
       "      <td>1.905269</td>\n",
       "      <td>1.653583</td>\n",
       "      <td>0.294541</td>\n",
       "      <td>-1.655865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43275</th>\n",
       "      <td>40399</td>\n",
       "      <td>480</td>\n",
       "      <td>[1544.0, 1544.0, 1544.0, 1536.0, 1544.0, 1552....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.494347</td>\n",
       "      <td>-0.708495</td>\n",
       "      <td>-0.932051</td>\n",
       "      <td>-0.243978</td>\n",
       "      <td>-1.121965</td>\n",
       "      <td>-0.497518</td>\n",
       "      <td>-0.816817</td>\n",
       "      <td>1.647459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43354</th>\n",
       "      <td>40407</td>\n",
       "      <td>0</td>\n",
       "      <td>[1464.0, 1464.0, 1456.0, 1456.0, 1456.0, 1456....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.769446</td>\n",
       "      <td>-0.553501</td>\n",
       "      <td>-0.808075</td>\n",
       "      <td>-0.185196</td>\n",
       "      <td>-0.182767</td>\n",
       "      <td>-0.631067</td>\n",
       "      <td>-0.723728</td>\n",
       "      <td>-0.101360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43355</th>\n",
       "      <td>40407</td>\n",
       "      <td>80</td>\n",
       "      <td>[1640.0, 1640.0, 1648.0, 1640.0, 1648.0, 1648....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.576799</td>\n",
       "      <td>0.957691</td>\n",
       "      <td>0.533411</td>\n",
       "      <td>0.749316</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.424616</td>\n",
       "      <td>-1.332010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43356</th>\n",
       "      <td>40407</td>\n",
       "      <td>160</td>\n",
       "      <td>[2352.0, 2344.0, 2328.0, 2360.0, 2424.0, 2472....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.059013</td>\n",
       "      <td>0.776865</td>\n",
       "      <td>1.204155</td>\n",
       "      <td>1.475848</td>\n",
       "      <td>-0.067520</td>\n",
       "      <td>-0.609960</td>\n",
       "      <td>1.132794</td>\n",
       "      <td>-0.360444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43357</th>\n",
       "      <td>40407</td>\n",
       "      <td>240</td>\n",
       "      <td>[1616.0, 1616.0, 1616.0, 1624.0, 1616.0, 1624....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.421463</td>\n",
       "      <td>0.712284</td>\n",
       "      <td>0.479370</td>\n",
       "      <td>0.327724</td>\n",
       "      <td>0.857629</td>\n",
       "      <td>0.314399</td>\n",
       "      <td>0.334920</td>\n",
       "      <td>0.740664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43358</th>\n",
       "      <td>40407</td>\n",
       "      <td>320</td>\n",
       "      <td>[1792.0, 1784.0, 1784.0, 1720.0, 1624.0, 1552....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>-0.346842</td>\n",
       "      <td>-0.035210</td>\n",
       "      <td>-0.425435</td>\n",
       "      <td>-0.533730</td>\n",
       "      <td>-0.259297</td>\n",
       "      <td>-0.133367</td>\n",
       "      <td>1.064520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43359</th>\n",
       "      <td>40407</td>\n",
       "      <td>400</td>\n",
       "      <td>[1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1624....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.369685</td>\n",
       "      <td>0.983523</td>\n",
       "      <td>0.439634</td>\n",
       "      <td>0.899305</td>\n",
       "      <td>0.625688</td>\n",
       "      <td>-0.175679</td>\n",
       "      <td>0.363299</td>\n",
       "      <td>-1.137697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43360</th>\n",
       "      <td>40407</td>\n",
       "      <td>480</td>\n",
       "      <td>[2392.0, 2456.0, 2520.0, 2528.0, 2520.0, 2328....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.251659</td>\n",
       "      <td>0.841445</td>\n",
       "      <td>-0.114550</td>\n",
       "      <td>0.675858</td>\n",
       "      <td>1.185258</td>\n",
       "      <td>0.459662</td>\n",
       "      <td>-0.122743</td>\n",
       "      <td>-1.396781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43361</th>\n",
       "      <td>40407</td>\n",
       "      <td>560</td>\n",
       "      <td>[1616.0, 1624.0, 1632.0, 1624.0, 1616.0, 1616....</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.251659</td>\n",
       "      <td>2.171811</td>\n",
       "      <td>1.000177</td>\n",
       "      <td>2.556940</td>\n",
       "      <td>0.589324</td>\n",
       "      <td>-0.214397</td>\n",
       "      <td>1.192902</td>\n",
       "      <td>-1.072926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43362</th>\n",
       "      <td>40407</td>\n",
       "      <td>640</td>\n",
       "      <td>[3320.0, 3304.0, 3288.0, 2976.0, 2328.0, 1784....</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.665889</td>\n",
       "      <td>2.120146</td>\n",
       "      <td>-0.174419</td>\n",
       "      <td>1.406600</td>\n",
       "      <td>1.801086</td>\n",
       "      <td>1.388629</td>\n",
       "      <td>-0.064409</td>\n",
       "      <td>-1.655865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43399</th>\n",
       "      <td>40413</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1400.0, 1400.0, 1400.0, 1384.0, 1384....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.183675</td>\n",
       "      <td>-0.630998</td>\n",
       "      <td>-1.356432</td>\n",
       "      <td>-0.308716</td>\n",
       "      <td>0.860798</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>-1.119154</td>\n",
       "      <td>-1.396781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43400</th>\n",
       "      <td>40413</td>\n",
       "      <td>80</td>\n",
       "      <td>[1608.0, 1600.0, 1584.0, 1568.0, 1568.0, 1568....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.059013</td>\n",
       "      <td>1.358092</td>\n",
       "      <td>0.869843</td>\n",
       "      <td>1.630838</td>\n",
       "      <td>0.413211</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>0.858710</td>\n",
       "      <td>-0.878612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43401</th>\n",
       "      <td>40413</td>\n",
       "      <td>160</td>\n",
       "      <td>[2552.0, 2536.0, 2528.0, 2520.0, 2504.0, 2504....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214349</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>2.315702</td>\n",
       "      <td>1.528212</td>\n",
       "      <td>-0.581283</td>\n",
       "      <td>-0.656987</td>\n",
       "      <td>2.224663</td>\n",
       "      <td>0.805435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43402</th>\n",
       "      <td>40413</td>\n",
       "      <td>240</td>\n",
       "      <td>[2168.0, 2160.0, 2152.0, 2136.0, 2136.0, 2128....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.199881</td>\n",
       "      <td>2.740122</td>\n",
       "      <td>4.463035</td>\n",
       "      <td>3.660873</td>\n",
       "      <td>-0.329292</td>\n",
       "      <td>-0.595873</td>\n",
       "      <td>5.226748</td>\n",
       "      <td>0.675893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>40413</td>\n",
       "      <td>320</td>\n",
       "      <td>[1640.0, 1640.0, 1640.0, 1640.0, 1640.0, 1640....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.576799</td>\n",
       "      <td>-0.463088</td>\n",
       "      <td>0.126515</td>\n",
       "      <td>-0.553626</td>\n",
       "      <td>-1.384329</td>\n",
       "      <td>-0.258334</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>1.906543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>40413</td>\n",
       "      <td>400</td>\n",
       "      <td>[1674.0, 1682.0, 1682.0, 1698.0, 1698.0, 1698....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>-0.463088</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>-0.566286</td>\n",
       "      <td>-0.798700</td>\n",
       "      <td>-0.498580</td>\n",
       "      <td>-0.034485</td>\n",
       "      <td>0.934977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>40413</td>\n",
       "      <td>480</td>\n",
       "      <td>[1712.0, 1712.0, 1704.0, 1704.0, 1712.0, 1720....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.597905</td>\n",
       "      <td>-0.450171</td>\n",
       "      <td>-0.009117</td>\n",
       "      <td>-0.076683</td>\n",
       "      <td>-2.047634</td>\n",
       "      <td>0.306796</td>\n",
       "      <td>-0.099747</td>\n",
       "      <td>2.359941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>40413</td>\n",
       "      <td>560</td>\n",
       "      <td>[1352.0, 1360.0, 1368.0, 1384.0, 1376.0, 1368....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.287233</td>\n",
       "      <td>-0.605165</td>\n",
       "      <td>-1.465573</td>\n",
       "      <td>-0.508589</td>\n",
       "      <td>3.293455</td>\n",
       "      <td>5.929047</td>\n",
       "      <td>-1.198162</td>\n",
       "      <td>-0.554757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>40414</td>\n",
       "      <td>0</td>\n",
       "      <td>[1400.0, 1400.0, 1392.0, 1392.0, 1392.0, 1400....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.183675</td>\n",
       "      <td>-0.889321</td>\n",
       "      <td>-1.479348</td>\n",
       "      <td>-0.610471</td>\n",
       "      <td>0.606450</td>\n",
       "      <td>1.001333</td>\n",
       "      <td>-1.208473</td>\n",
       "      <td>-0.489986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>40414</td>\n",
       "      <td>80</td>\n",
       "      <td>[1512.0, 1544.0, 1560.0, 1584.0, 1592.0, 1600....</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.251659</td>\n",
       "      <td>-0.101435</td>\n",
       "      <td>0.616062</td>\n",
       "      <td>-0.204372</td>\n",
       "      <td>-1.501973</td>\n",
       "      <td>-0.094584</td>\n",
       "      <td>0.419669</td>\n",
       "      <td>2.036085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>40414</td>\n",
       "      <td>160</td>\n",
       "      <td>[1800.0, 1816.0, 1808.0, 1816.0, 1808.0, 1800....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.457037</td>\n",
       "      <td>-0.308094</td>\n",
       "      <td>0.660037</td>\n",
       "      <td>-0.626094</td>\n",
       "      <td>-0.397119</td>\n",
       "      <td>-0.431251</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.352038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43410</th>\n",
       "      <td>40414</td>\n",
       "      <td>240</td>\n",
       "      <td>[1792.0, 1792.0, 1792.0, 1800.0, 1800.0, 1800....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.457037</td>\n",
       "      <td>-0.308094</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>-0.630603</td>\n",
       "      <td>-0.434697</td>\n",
       "      <td>-0.415297</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.028182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43411</th>\n",
       "      <td>40414</td>\n",
       "      <td>320</td>\n",
       "      <td>[1784.0, 1784.0, 1784.0, 1792.0, 1800.0, 1792....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.457037</td>\n",
       "      <td>-0.321010</td>\n",
       "      <td>0.622420</td>\n",
       "      <td>-0.629201</td>\n",
       "      <td>-0.397927</td>\n",
       "      <td>-0.498360</td>\n",
       "      <td>0.415959</td>\n",
       "      <td>0.675893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43412</th>\n",
       "      <td>40414</td>\n",
       "      <td>400</td>\n",
       "      <td>[1790.0, 1782.0, 1774.0, 1750.0, 1742.0, 1734....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.576799</td>\n",
       "      <td>-0.298406</td>\n",
       "      <td>0.320029</td>\n",
       "      <td>-0.338771</td>\n",
       "      <td>-0.799734</td>\n",
       "      <td>-0.595415</td>\n",
       "      <td>0.161944</td>\n",
       "      <td>1.388375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43473</th>\n",
       "      <td>40421</td>\n",
       "      <td>0</td>\n",
       "      <td>[1416.0, 1400.0, 1400.0, 1408.0, 1408.0, 1408....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.080118</td>\n",
       "      <td>-0.618082</td>\n",
       "      <td>-1.352723</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>1.495001</td>\n",
       "      <td>0.924997</td>\n",
       "      <td>-1.119345</td>\n",
       "      <td>-1.655865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43474</th>\n",
       "      <td>40421</td>\n",
       "      <td>80</td>\n",
       "      <td>[1632.0, 1632.0, 1632.0, 1632.0, 1616.0, 1616....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214349</td>\n",
       "      <td>0.621871</td>\n",
       "      <td>0.119627</td>\n",
       "      <td>0.265711</td>\n",
       "      <td>1.339241</td>\n",
       "      <td>0.730346</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>-0.878612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43475</th>\n",
       "      <td>40421</td>\n",
       "      <td>160</td>\n",
       "      <td>[2048.0, 2000.0, 1920.0, 1848.0, 1808.0, 1792....</td>\n",
       "      <td>False</td>\n",
       "      <td>0.887471</td>\n",
       "      <td>0.066475</td>\n",
       "      <td>0.360163</td>\n",
       "      <td>-0.367707</td>\n",
       "      <td>1.853757</td>\n",
       "      <td>1.841609</td>\n",
       "      <td>0.195008</td>\n",
       "      <td>-1.267239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43476</th>\n",
       "      <td>40421</td>\n",
       "      <td>240</td>\n",
       "      <td>[1728.0, 1736.0, 1744.0, 1744.0, 1736.0, 1728....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.154525</td>\n",
       "      <td>3.037194</td>\n",
       "      <td>0.766529</td>\n",
       "      <td>2.660313</td>\n",
       "      <td>0.580099</td>\n",
       "      <td>-0.057501</td>\n",
       "      <td>1.012949</td>\n",
       "      <td>-1.202468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43477</th>\n",
       "      <td>40421</td>\n",
       "      <td>320</td>\n",
       "      <td>[1186.0, 1202.0, 1202.0, 1234.0, 1242.0, 1258....</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.361640</td>\n",
       "      <td>-0.437255</td>\n",
       "      <td>-0.791254</td>\n",
       "      <td>0.596691</td>\n",
       "      <td>-0.644265</td>\n",
       "      <td>-0.669319</td>\n",
       "      <td>-0.653055</td>\n",
       "      <td>0.805435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43478</th>\n",
       "      <td>40421</td>\n",
       "      <td>400</td>\n",
       "      <td>[1728.0, 1728.0, 1728.0, 1728.0, 1728.0, 1728....</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.546126</td>\n",
       "      <td>-0.437255</td>\n",
       "      <td>-1.192719</td>\n",
       "      <td>-0.011958</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>-0.227572</td>\n",
       "      <td>-0.992419</td>\n",
       "      <td>-1.072926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4130 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       serie  ind_debut                                            valeurs  \\\n",
       "id                                                                           \n",
       "0          0          0  [1424.0, 1432.0, 1432.0, 1416.0, 1408.0, 1408....   \n",
       "1          0         80  [1696.0, 1704.0, 1704.0, 1712.0, 1704.0, 1696....   \n",
       "2          0        160  [1696.0, 1664.0, 1632.0, 1624.0, 1616.0, 1624....   \n",
       "3          0        240  [2056.0, 2056.0, 2056.0, 2048.0, 2008.0, 1808....   \n",
       "4          0        320  [1664.0, 1664.0, 1664.0, 1664.0, 1656.0, 1656....   \n",
       "5          0        400  [1680.0, 1680.0, 1672.0, 1664.0, 1672.0, 1672....   \n",
       "6          0        480  [1656.0, 1672.0, 1672.0, 1672.0, 1672.0, 1664....   \n",
       "7          0        560  [1664.0, 1672.0, 1664.0, 1664.0, 1672.0, 1672....   \n",
       "8          1          0  [1400.0, 1384.0, 1384.0, 1392.0, 1400.0, 1400....   \n",
       "9          1         80  [1736.0, 1736.0, 1736.0, 1744.0, 1744.0, 1744....   \n",
       "10         1        160  [1704.0, 1704.0, 1704.0, 1712.0, 1712.0, 1704....   \n",
       "11         1        240  [1840.0, 1816.0, 1784.0, 1760.0, 1728.0, 1696....   \n",
       "12         1        320  [1672.0, 1672.0, 1672.0, 1672.0, 1672.0, 1680....   \n",
       "13         1        400  [1680.0, 1680.0, 1680.0, 1680.0, 1696.0, 1704....   \n",
       "14         2          0  [1416.0, 1424.0, 1424.0, 1424.0, 1424.0, 1416....   \n",
       "15         2         80  [1696.0, 1688.0, 1680.0, 1680.0, 1688.0, 1688....   \n",
       "16         2        160  [1680.0, 1672.0, 1672.0, 1672.0, 1672.0, 1664....   \n",
       "17         2        240  [1664.0, 1672.0, 1680.0, 1688.0, 1680.0, 1672....   \n",
       "18         2        320  [1672.0, 1672.0, 1680.0, 1680.0, 1680.0, 1688....   \n",
       "19         2        400  [1672.0, 1680.0, 1688.0, 1680.0, 1680.0, 1680....   \n",
       "20         2        480  [1656.0, 1664.0, 1664.0, 1672.0, 1672.0, 1672....   \n",
       "21         2        560  [1672.0, 1664.0, 1664.0, 1664.0, 1672.0, 1672....   \n",
       "22         2        640  [1680.0, 1680.0, 1672.0, 1672.0, 1672.0, 1664....   \n",
       "23         2        720  [1672.0, 1664.0, 1664.0, 1664.0, 1664.0, 1672....   \n",
       "24         3          0  [1400.0, 1392.0, 1384.0, 1376.0, 1384.0, 1392....   \n",
       "25         3         80  [1360.0, 1392.0, 1480.0, 1632.0, 1720.0, 1768....   \n",
       "26         3        160  [1672.0, 1656.0, 1648.0, 1664.0, 1664.0, 1664....   \n",
       "27         3        240  [1672.0, 1672.0, 1680.0, 1680.0, 1664.0, 1656....   \n",
       "28         3        320  [1672.0, 1656.0, 1656.0, 1664.0, 1672.0, 1672....   \n",
       "29         3        400  [1680.0, 1672.0, 1672.0, 1672.0, 1680.0, 1680....   \n",
       "...      ...        ...                                                ...   \n",
       "43275  40399        480  [1544.0, 1544.0, 1544.0, 1536.0, 1544.0, 1552....   \n",
       "43354  40407          0  [1464.0, 1464.0, 1456.0, 1456.0, 1456.0, 1456....   \n",
       "43355  40407         80  [1640.0, 1640.0, 1648.0, 1640.0, 1648.0, 1648....   \n",
       "43356  40407        160  [2352.0, 2344.0, 2328.0, 2360.0, 2424.0, 2472....   \n",
       "43357  40407        240  [1616.0, 1616.0, 1616.0, 1624.0, 1616.0, 1624....   \n",
       "43358  40407        320  [1792.0, 1784.0, 1784.0, 1720.0, 1624.0, 1552....   \n",
       "43359  40407        400  [1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1624....   \n",
       "43360  40407        480  [2392.0, 2456.0, 2520.0, 2528.0, 2520.0, 2328....   \n",
       "43361  40407        560  [1616.0, 1624.0, 1632.0, 1624.0, 1616.0, 1616....   \n",
       "43362  40407        640  [3320.0, 3304.0, 3288.0, 2976.0, 2328.0, 1784....   \n",
       "43399  40413          0  [1400.0, 1400.0, 1400.0, 1400.0, 1384.0, 1384....   \n",
       "43400  40413         80  [1608.0, 1600.0, 1584.0, 1568.0, 1568.0, 1568....   \n",
       "43401  40413        160  [2552.0, 2536.0, 2528.0, 2520.0, 2504.0, 2504....   \n",
       "43402  40413        240  [2168.0, 2160.0, 2152.0, 2136.0, 2136.0, 2128....   \n",
       "43403  40413        320  [1640.0, 1640.0, 1640.0, 1640.0, 1640.0, 1640....   \n",
       "43404  40413        400  [1674.0, 1682.0, 1682.0, 1698.0, 1698.0, 1698....   \n",
       "43405  40413        480  [1712.0, 1712.0, 1704.0, 1704.0, 1712.0, 1720....   \n",
       "43406  40413        560  [1352.0, 1360.0, 1368.0, 1384.0, 1376.0, 1368....   \n",
       "43407  40414          0  [1400.0, 1400.0, 1392.0, 1392.0, 1392.0, 1400....   \n",
       "43408  40414         80  [1512.0, 1544.0, 1560.0, 1584.0, 1592.0, 1600....   \n",
       "43409  40414        160  [1800.0, 1816.0, 1808.0, 1816.0, 1808.0, 1800....   \n",
       "43410  40414        240  [1792.0, 1792.0, 1792.0, 1800.0, 1800.0, 1800....   \n",
       "43411  40414        320  [1784.0, 1784.0, 1784.0, 1792.0, 1800.0, 1792....   \n",
       "43412  40414        400  [1790.0, 1782.0, 1774.0, 1750.0, 1742.0, 1734....   \n",
       "43473  40421          0  [1416.0, 1400.0, 1400.0, 1408.0, 1408.0, 1408....   \n",
       "43474  40421         80  [1632.0, 1632.0, 1632.0, 1632.0, 1616.0, 1616....   \n",
       "43475  40421        160  [2048.0, 2000.0, 1920.0, 1848.0, 1808.0, 1792....   \n",
       "43476  40421        240  [1728.0, 1736.0, 1744.0, 1744.0, 1736.0, 1728....   \n",
       "43477  40421        320  [1186.0, 1202.0, 1202.0, 1234.0, 1242.0, 1258....   \n",
       "43478  40421        400  [1728.0, 1728.0, 1728.0, 1728.0, 1728.0, 1728....   \n",
       "\n",
       "        anom       min       max      mean       std      skew      kurt  \\\n",
       "id                                                                         \n",
       "0      False -1.028339 -0.385591 -0.752975  0.072871 -0.277912 -0.646449   \n",
       "1      False  0.835693  1.810158  0.937659  1.343193  0.937661  0.173286   \n",
       "2      False  0.421463  1.164350  1.960728  0.723111 -0.605105 -0.461779   \n",
       "3      False  0.317906  0.079391  0.068765 -0.146684  1.517035  0.918398   \n",
       "4      False  0.576799 -0.514752 -0.043555 -0.622430 -0.469716 -0.376161   \n",
       "5      False  0.421463  1.629332  0.520696  0.811596  1.278931  0.771192   \n",
       "6      False  0.473242 -0.217680  0.027970 -0.484805  2.149219  2.536853   \n",
       "7      False -1.753241  2.494715  0.929712  3.107377  0.470043 -0.265795   \n",
       "8      False -1.183675 -0.217680 -1.312987 -0.073798  1.375516  0.706834   \n",
       "9      False  0.835693 -0.411423  0.196450 -0.574115  0.035627 -0.392720   \n",
       "10     False  0.525021  1.810158  0.962560  0.935434  0.969925  0.485903   \n",
       "11     False  0.317906  2.120146  1.719133  1.302393  0.479276  0.036591   \n",
       "12     False  0.783914 -0.501836  0.064527 -0.640654 -0.678098 -0.458010   \n",
       "13     False -1.649683  0.363547 -0.816552  0.309408  0.094834 -0.245674   \n",
       "14     False -1.028339 -0.308094 -0.792711  0.152231 -0.148238 -0.612016   \n",
       "15     False  0.628578  0.105224  0.287578 -0.206944  0.916802  0.353261   \n",
       "16     False  0.732135 -0.476004  0.063997 -0.623573 -0.214216 -0.369946   \n",
       "17     False  0.732135 -0.488920  0.032738 -0.627769 -0.121607 -0.351018   \n",
       "18     False  0.732135 -0.501836  0.023731 -0.622130 -0.178157 -0.504242   \n",
       "19     False  0.680357 -0.501836  0.006247 -0.620257 -0.434229 -0.513466   \n",
       "20     False  0.628578 -0.527668 -0.021303 -0.636495 -0.796507 -0.337467   \n",
       "21     False  0.680357 -0.514752 -0.013885 -0.631961 -0.344989 -0.455776   \n",
       "22     False  0.628578 -0.514752 -0.016005 -0.630546 -0.680619 -0.395817   \n",
       "23     False -1.753241 -0.514752 -0.702113  0.175564 -0.733851 -0.643377   \n",
       "24     False -1.235454 -0.966818 -1.492064 -0.621531 -0.756188 -0.395522   \n",
       "25     False -1.235454 -0.372674 -0.036667 -0.353589 -2.445456  1.522810   \n",
       "26     False  0.266127  1.939320  1.078059  1.645343  0.800956  0.066936   \n",
       "27     False  0.628578 -0.514752 -0.016005 -0.627265 -0.623009 -0.429534   \n",
       "28     False  0.628578 -0.514752  0.000949 -0.629536 -0.970776 -0.333396   \n",
       "29     False  0.473242  1.861823  0.363871  0.865705  1.905269  1.653583   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "43275  False -1.494347 -0.708495 -0.932051 -0.243978 -1.121965 -0.497518   \n",
       "43354  False -0.769446 -0.553501 -0.808075 -0.185196 -0.182767 -0.631067   \n",
       "43355  False  0.576799  0.957691  0.533411  0.749316  0.833100  0.015235   \n",
       "43356  False  0.059013  0.776865  1.204155  1.475848 -0.067520 -0.609960   \n",
       "43357  False  0.421463  0.712284  0.479370  0.327724  0.857629  0.314399   \n",
       "43358  False  0.007234 -0.346842 -0.035210 -0.425435 -0.533730 -0.259297   \n",
       "43359  False  0.369685  0.983523  0.439634  0.899305  0.625688 -0.175679   \n",
       "43360  False -0.251659  0.841445 -0.114550  0.675858  1.185258  0.459662   \n",
       "43361   True -0.251659  2.171811  1.000177  2.556940  0.589324 -0.214397   \n",
       "43362   True -0.665889  2.120146 -0.174419  1.406600  1.801086  1.388629   \n",
       "43399  False -1.183675 -0.630998 -1.356432 -0.308716  0.860798  0.052560   \n",
       "43400  False  0.059013  1.358092  0.869843  1.630838  0.413211 -0.344000   \n",
       "43401  False  0.214349  0.880194  2.315702  1.528212 -0.581283 -0.656987   \n",
       "43402  False -0.199881  2.740122  4.463035  3.660873 -0.329292 -0.595873   \n",
       "43403  False  0.576799 -0.463088  0.126515 -0.553626 -1.384329 -0.258334   \n",
       "43404   True  0.589744 -0.463088  0.088766 -0.566286 -0.798700 -0.498580   \n",
       "43405  False -1.597905 -0.450171 -0.009117 -0.076683 -2.047634  0.306796   \n",
       "43406  False -1.287233 -0.605165 -1.465573 -0.508589  3.293455  5.929047   \n",
       "43407  False -1.183675 -0.889321 -1.479348 -0.610471  0.606450  1.001333   \n",
       "43408  False -0.251659 -0.101435  0.616062 -0.204372 -1.501973 -0.094584   \n",
       "43409  False  1.457037 -0.308094  0.660037 -0.626094 -0.397119 -0.431251   \n",
       "43410  False  1.457037 -0.308094  0.650500 -0.630603 -0.434697 -0.415297   \n",
       "43411  False  1.457037 -0.321010  0.622420 -0.629201 -0.397927 -0.498360   \n",
       "43412   True  0.576799 -0.298406  0.320029 -0.338771 -0.799734 -0.595415   \n",
       "43473  False -1.080118 -0.618082 -1.352723 -0.412127  1.495001  0.924997   \n",
       "43474  False  0.214349  0.621871  0.119627  0.265711  1.339241  0.730346   \n",
       "43475  False  0.887471  0.066475  0.360163 -0.367707  1.853757  1.841609   \n",
       "43476   True -2.154525  3.037194  0.766529  2.660313  0.580099 -0.057501   \n",
       "43477   True -2.361640 -0.437255 -0.791254  0.596691 -0.644265 -0.669319   \n",
       "43478  False -1.546126 -0.437255 -1.192719 -0.011958  0.534928 -0.227572   \n",
       "\n",
       "         energy  average_cross  \n",
       "id                              \n",
       "0     -0.669422       0.157725  \n",
       "1      0.866756      -1.072926  \n",
       "2      1.744010       1.064520  \n",
       "3     -0.039608      -1.720636  \n",
       "4     -0.142609       1.388375  \n",
       "5      0.421346      -1.072926  \n",
       "6     -0.083170      -0.230902  \n",
       "7      1.292936      -1.008155  \n",
       "8     -1.079589      -1.591094  \n",
       "9      0.054318      -0.101360  \n",
       "10     0.826520      -0.230902  \n",
       "11     1.589782       0.546351  \n",
       "12    -0.054783       0.675893  \n",
       "13    -0.699158       0.157725  \n",
       "14    -0.693595      -0.101360  \n",
       "15     0.139156      -0.554757  \n",
       "16    -0.055157       0.481580  \n",
       "17    -0.080702       0.805435  \n",
       "18    -0.088017       0.028182  \n",
       "19    -0.102234      -0.101360  \n",
       "20    -0.124654       0.546351  \n",
       "21    -0.118626       0.675893  \n",
       "22    -0.120339       0.870206  \n",
       "23    -0.624564       0.934977  \n",
       "24    -1.217122       0.999748  \n",
       "25    -0.132818       1.453146  \n",
       "26     1.049266      -0.749070  \n",
       "27    -0.120327       0.934977  \n",
       "28    -0.106577       1.712230  \n",
       "29     0.294541      -1.655865  \n",
       "...         ...            ...  \n",
       "43275 -0.816817       1.647459  \n",
       "43354 -0.723728      -0.101360  \n",
       "43355  0.424616      -1.332010  \n",
       "43356  1.132794      -0.360444  \n",
       "43357  0.334920       0.740664  \n",
       "43358 -0.133367       1.064520  \n",
       "43359  0.363299      -1.137697  \n",
       "43360 -0.122743      -1.396781  \n",
       "43361  1.192902      -1.072926  \n",
       "43362 -0.064409      -1.655865  \n",
       "43399 -1.119154      -1.396781  \n",
       "43400  0.858710      -0.878612  \n",
       "43401  2.224663       0.805435  \n",
       "43402  5.226748       0.675893  \n",
       "43403 -0.003330       1.906543  \n",
       "43404 -0.034485       0.934977  \n",
       "43405 -0.099747       2.359941  \n",
       "43406 -1.198162      -0.554757  \n",
       "43407 -1.208473      -0.489986  \n",
       "43408  0.419669       2.036085  \n",
       "43409  0.448736       0.352038  \n",
       "43410  0.440400       0.028182  \n",
       "43411  0.415959       0.675893  \n",
       "43412  0.161944       1.388375  \n",
       "43473 -1.119345      -1.655865  \n",
       "43474  0.027752      -0.878612  \n",
       "43475  0.195008      -1.267239  \n",
       "43476  1.012949      -1.202468  \n",
       "43477 -0.653055       0.805435  \n",
       "43478 -0.992419      -1.072926  \n",
       "\n",
       "[4130 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1cebee3cbe4d6ba755f56c461380ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Choix_df', options=('Features', 'Ondelettes_haar', 'Ondelettes_db2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(Choix_df=df_liste, taille_test=widgets.IntSlider(min=100, max=taille_max - 100, step=100, \n",
    "                                                           value=taille_max//3, continuous_update=False), \n",
    "          button=widgets.ToggleButton(description=\"Refresh\"))\n",
    "\n",
    "def RandomForest(Choix_df, taille_test, button):\n",
    "    df_coeff = dict_df[Choix_df]\n",
    "    #print(\"Proportion de fenêtres utilisées pour l'apprentissage : \", 1 - taille_test / df_coeff.shape[0])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_coeff, df_supervise[\"anom\"], test_size=taille_test)\n",
    "    \n",
    "    # définition des paramètres\n",
    "    \n",
    "    # apprentissage\n",
    "    \n",
    "    max_feat = 5\n",
    "    param = [{\"max_features\" : list(range(2, min(max_feat, df_coeff.shape[1]) + 1))}]\n",
    "    rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "\n",
    "    rfOpt = rf.fit(X_train, Y_train)\n",
    "    \n",
    "    #print(\"Erreur Out of bag : \", 1 - rfOpt.oob_score_)  # N'existe pas sur les objets GridSearchCV, hélas\n",
    "    # erreur de prévision sur le test\n",
    "    #print(\"Erreur de prévision sur le test : \", 1 - rfOpt.score(X_test, Y_test))\n",
    "    # paramètre optimal\n",
    "    #print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                    min_samples_leaf=1, max_features=rfOpt.best_params_['max_features'], \n",
    "                                    max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "    rfFit = forest.fit(X_train, Y_train)\n",
    "    \n",
    "    # prévision\n",
    "    y_chap = rfOpt.predict(X_test)\n",
    "    df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "    ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "    print(ind_series_anom)\n",
    "    # matrice de confusion\n",
    "\n",
    "    table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "    table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False)\n",
    "    table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "    table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "    sns.set(font_scale=1.4)  #for label size\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "    sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "    ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "    sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "    sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "    sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "    plt.show()\n",
    "\n",
    "    for num in ind_series_anom:\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        TS = df_supervise[(df_supervise[\"serie\"] == num)][\"valeurs\"].values\n",
    "        anoms = df_supervise[df_supervise[\"serie\"] == num][\"pred\"].values\n",
    "        title_obj = plt.title(\"Série numéro \" + str(num % offset), size=25)\n",
    "        for (i, x), anom in zip(enumerate(TS), anoms):\n",
    "\n",
    "            if i > 0:  # Raccordement\n",
    "                ax.plot([N * i - 1, N * i], [last, x[0]], \"br\"[int(anom)])\n",
    "\n",
    "            ax.plot(range(N * i, N * (i + 1)),  x, \"br\"[int(anom)])\n",
    "            last = x[-1]\n",
    "            if anom:\n",
    "                plt.setp(title_obj, color='r', fontweight=\"bold\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :**\n",
    "\n",
    "Très peu d'erreur avec les coefficients d'ondelettes (haar ou db2) et même parfois 0 erreur.\n",
    "\n",
    "Avec les coefficients de Fourier : résulats quasi identiques à ceux de Features, parfois meilleurs, parfois pires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A FINIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prévision sur le test :  0.0\n",
      "Meilleur score = 0.000000, Meilleur paramètre = {'max_features': 2}\n"
     ]
    }
   ],
   "source": [
    "# RandomForest sur coefficients d'ondelettes db2\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Coeff_ond_db2, df_supervise[\"anom\"],\n",
    "                                                    test_size=Coeff_ond_db2.shape[1] // 3)\n",
    "\n",
    "max_feat = 16\n",
    "param = [{\"max_features\" : list(range(2, min(max_feat, Coeff_ond_db2.shape[1]) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "\n",
    "# erreur de prévision sur le test\n",
    "print(\"Erreur de prévision sur le test : \", 1 - rfOpt.score(X_test, Y_test))\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))\n",
    "\n",
    "# forest optimal\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, max_features=2, max_leaf_nodes=None, bootstrap=True,\n",
    "                                oob_score=True)\n",
    "rfFit = forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance de chaque coefficient :  [0.01544503 0.01551222 0.0165403  0.01981161 0.01397472 0.01408764\n",
      " 0.01710532 0.00895099 0.00935629 0.01097886 0.01021018 0.00990826\n",
      " 0.00793469 0.00909728 0.00984455 0.00906341 0.01109107 0.01116616\n",
      " 0.01051841 0.01431021 0.01214844 0.01036568 0.01019262 0.00929932\n",
      " 0.00948328 0.00832366 0.00940433 0.01177361 0.01254009 0.01345662\n",
      " 0.00927954 0.00858882 0.00957946 0.01298913 0.01127858 0.01144453\n",
      " 0.01262432 0.01111172 0.01187968 0.01085528 0.00830008 0.01529231\n",
      " 0.00987158 0.00748411 0.01050888 0.00917801 0.00844444 0.01095494\n",
      " 0.00730613 0.01221827 0.00892703 0.010967   0.01008004 0.01028508\n",
      " 0.01347315 0.01780571 0.01991568 0.00914479 0.0132928  0.01113185\n",
      " 0.01169865 0.00992362 0.01125908 0.00796507 0.00802061 0.0129269\n",
      " 0.02009876 0.01050927 0.01386637 0.01081848 0.01145549 0.00978363\n",
      " 0.01198103 0.00926106 0.00852744 0.01732983 0.01353449 0.00987312\n",
      " 0.01693452 0.00746629 0.00692699 0.0079258  0.00868321 0.00764668\n",
      " 0.00875718 0.01382063 0.01179937 0.00903439 0.00606425]\n"
     ]
    }
   ],
   "source": [
    "print(\"Importance de chaque coefficient : \", rfFit.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_chap = rfOpt.predict(X_test)\n",
    "y_chap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = rfFit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 56,  3, 55, 75,  6, 78,  2,  1,  0, 41, 19,  5,  4, 68, 85, 76,\n",
       "       54, 29, 58, 33, 65, 36, 28, 49, 20, 72, 38, 86, 27, 60, 70, 35, 34,\n",
       "       62, 17, 59, 37, 16,  9, 51, 47, 39, 69, 18, 67, 44, 21, 53, 10, 22,\n",
       "       52, 61, 11, 77, 42, 14, 71, 32, 24, 26,  8, 23, 30, 73, 45, 57, 13,\n",
       "       15, 87,  7, 50, 84, 82, 31, 74, 46, 25, 40, 64, 63, 12, 81, 83, 43,\n",
       "       79, 48, 80, 88], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients triés par ordre d'importance\n",
    "np.argsort(rfFit.feature_importances_)[::-1] #dans l'ordre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.65101815e+03,  6.62605163e+03,  6.83186869e+03,  6.67265766e+03,\n",
       "        0.00000000e+00,  0.00000000e+00,  6.65501598e+03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.68428512e+01,\n",
       "        7.83836718e+01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -4.89897949e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -3.86370331e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.82842712e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on ne garde que les 10 coefficients les plus importants pour reconstruire un signal avec anomalie\n",
    "seuil = np.sort(importance)[-10]\n",
    "valeurs = df_ond_db2.loc[6, :].values\n",
    "valeurs_seuil = np.array([v if imp >= seuil else 0 for imp, v in zip(importance, valeurs)])\n",
    "valeurs_seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coeff_slices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-58ce2a5c61e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaverecn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_to_coeffs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaleurs_seuil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoeff_slices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'db2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'coeff_slices' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(pywt.waverecn(pywt.array_to_coeffs(valeurs_seuil, coeff_slices), 'db2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le signal d'origine\n",
    "plt.plot(np.array(df_supervise.loc[6, \"valeurs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester regression logistique\n",
    "Pouvoir visualiser l'anomalie\n",
    "Tester lissage spline ou supprimer les niveaux de détails les plus fins en ondelettes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervise[\"min\"] = list(map(min, df_supervise.valeurs))\n",
    "df_supervise[\"max\"] = list(map(max, df_supervise.valeurs))\n",
    "df_supervise[\"mean\"] = list(map(np.mean, df_supervise.valeurs))\n",
    "df_supervise[\"std\"] = list(map(np.std, df_supervise.valeurs))\n",
    "df_supervise[\"skew\"] = list(map(sps.skew, df_supervise.valeurs))\n",
    "df_supervise[\"kurt\"] = list(map(sps.kurtosis, df_supervise.valeurs))\n",
    "df_supervise[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), df_supervise.valeurs))\n",
    "df_supervise[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), df_supervise.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    data_fenetres[col] = scaler.fit_transform(data_fenetres[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_test = df_supervise.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_supervise[names_features], df_supervise[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Grille de valeurs du paramètre de pénalisaiton\n",
    "param=[{\"C\": [0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "logitL = GridSearchCV(LogisticRegression(penalty=\"l1\"), param, cv=5, n_jobs=-1)\n",
    "logitLasso = logitL.fit(X_train, Y_train)\n",
    "# Sélection du paramètre optimal\n",
    "logitLasso.best_params_[\"C\"]\n",
    "print(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" % (1.-logitLasso.best_score_,logitLasso.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des estimateurs\n",
    "logit= LogisticRegression(penalty=\"l1\")\n",
    "logitOpt=logit.fit(X_train, Y_train)\n",
    "# erreur sur l'échantillon test\n",
    "1-logitOpt.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"optimal\" obtenu est utilisé pour prédire l'échantillon test et estimer ainsi, sans biais, une erreur de prévision.\n",
    "\n",
    "La matrice de confusion croise les abomalies prédites avec celles effectivement présentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_chap = logitOpt.predict(X_test)\n",
    "df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "# matrice de confusion\n",
    "table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)  #for label size\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "LassoOpt=LogisticRegression(penalty=\"l1\",C=12)\n",
    "LassoOpt=LassoOpt.fit(X_train, Y_train)\n",
    "# Récupération des coefficients\n",
    "vect_coef=np.matrix.transpose(LassoOpt.coef_)\n",
    "vect_coef=vect_coef.ravel()\n",
    "#Affichage des 25 plus importants\n",
    "coef=pd.Series(abs(vect_coef),index=X_train.columns).sort_values(ascending=False)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "coef.plot(kind='bar')\n",
    "plt.title('Coeffients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les coefficients les plus importants dans le cas de features sont ceux de average_cross et skew. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grilles de valeurs du paramètre de pénalisation\n",
    "param=[{\"C\":[0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "logitR = GridSearchCV(LogisticRegression(penalty=\"l2\"), param, cv=5, n_jobs=-1)\n",
    "logitRidge = logitR.fit(X_train, Y_train)  \n",
    "# Sélection du paramètre optimal\n",
    "logitRidge.best_params_[\"C\"]\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1.-logitRidge.best_score_, logitRidge.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prévision\n",
    "y_chap = logitRidge.predict(X_test)\n",
    "df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "# matrice de confusion\n",
    "table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)  #for label size\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe ROC, Elle est utile pour comparer Lasso et Ridge \n",
    "from sklearn.metrics import roc_curve\n",
    "listMethod=[[\"Lasso\", logitLasso], [\"Ridge\", logitRidge]]\n",
    "\n",
    "for (name, method) in listMethod:\n",
    "    probas = method.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, probas[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1, label=str(name))\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient de Fourier et d'ondelettes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visulation par intéract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d05489ce5c74b719b5c8ff200a274a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Choix_df', options=('Features', 'Ondelettes_haar', 'Ondelettes_db2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(Choix_df=df_liste, taille_test=widgets.IntSlider(min=100, max=taille_max - 100, step=100, \n",
    "                                                           value=taille_max//3, continuous_update=False), \n",
    "          button=widgets.ToggleButton(description=\"Refresh\"))\n",
    "\n",
    "def RLLasso(Choix_df, taille_test, button):\n",
    "    df_coeff = dict_df[Choix_df]\n",
    "    print(\"Proportion de fenêtres utilisées pour l'apprentissage : \", 1 - taille_test / df_coeff.shape[0])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_coeff, df_supervise[\"anom\"], test_size=taille_test)\n",
    "    \n",
    "    param = [{\"C\": [0.5,1,5,10,12,15,30]}]\n",
    "    logitL = GridSearchCV(LogisticRegression(penalty=\"l1\"), param, cv=5, n_jobs=-1)\n",
    "    logitLasso = logitL.fit(X_train, Y_train)\n",
    "    # Sélection du paramètre optimal\n",
    "    logitLasso.best_params_[\"C\"]\n",
    "    print(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" %\n",
    "          (1.-logitLasso.best_score_,logitLasso.best_params_))\n",
    "    \n",
    "    # définition des estimateurs\n",
    "    logit= LogisticRegression(penalty=\"l1\")\n",
    "    logitOpt = logit.fit(X_train, Y_train)\n",
    "    # erreur sur l'échantillon test\n",
    "    print(\"Erreur sur l'échantillon test : \", 1-logitOpt.score(X_test, Y_test))\n",
    "\n",
    "    \n",
    "    # prévision\n",
    "    y_chap = logitOpt.predict(X_test)\n",
    "    df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "    ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "    # matrice de confusion\n",
    "    table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "    table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "    table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "    table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "    sns.set(font_scale=1.4)  #for label size\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "    sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "    ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "    sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "    sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "    sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
