{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "\n",
    "# Plot et Display\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Lecture des données \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_test = \"../../4A/Projet/Ensemble de test/\"\n",
    "path_test = \"../Donnees_projet/Ensemble_de_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('liste_propre', 'rb') as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    liste_propre, ind_recupere = mon_depickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(liste_propre)\n",
    "liste_appr = list(np.asarray(liste_propre)[np.asarray(ind_recupere) <= 299])\n",
    "liste_test = list(np.asarray(liste_propre)[np.asarray(ind_recupere) > 299])\n",
    "n_appr = len(liste_appr)\n",
    "n_test = len(liste_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom = [False] * n_test\n",
    "type_anom = [-1] * n_test\n",
    "loc = [-1] * n_test\n",
    "\n",
    "anom[73] = True\n",
    "type_anom[73] = 1\n",
    "loc[73] = 200\n",
    "\n",
    "anom[96] = True\n",
    "type_anom[96] = 1\n",
    "loc[96] = 300\n",
    "\n",
    "anom[36] = True\n",
    "type_anom[36] = 1\n",
    "loc[36] = 400\n",
    "\n",
    "anom[32] = True\n",
    "type_anom[32] = 1\n",
    "loc[32] = 300\n",
    "\n",
    "anom[33] = True\n",
    "type_anom[33] = 1\n",
    "loc[33] = 200\n",
    "\n",
    "anom[107] = True\n",
    "type_anom[107] = 2\n",
    "loc[107] = 600\n",
    "\n",
    "anom[60] = True\n",
    "type_anom[60] = 2\n",
    "loc[60] = 400\n",
    "\n",
    "anom[113] = True\n",
    "type_anom[113] = 2\n",
    "loc[113] = 400\n",
    "\n",
    "anom[9] = True\n",
    "type_anom[9] = 2\n",
    "loc[9] = 200\n",
    "\n",
    "anom[11] = True\n",
    "type_anom[11] = 2\n",
    "loc[11] = 300\n",
    "\n",
    "anom[53] = True\n",
    "type_anom[53] = 3\n",
    "loc[53] = 400\n",
    "\n",
    "anom[114] = True\n",
    "type_anom[114] = 3\n",
    "loc[114] = 400\n",
    "\n",
    "anom[14] = True\n",
    "type_anom[14] = 3\n",
    "loc[14] = 500\n",
    "\n",
    "anom[79] = True\n",
    "type_anom[79] = 3\n",
    "loc[79] = 400\n",
    "\n",
    "anom[29] = True\n",
    "type_anom[29] = 3\n",
    "loc[29] = 300\n",
    "\n",
    "anom[27] = True\n",
    "type_anom[27] = 4\n",
    "loc[27] = 300\n",
    "\n",
    "anom[121] = True\n",
    "type_anom[121] = 4\n",
    "loc[121] = 300\n",
    "\n",
    "anom[5] = True\n",
    "type_anom[5] = 4\n",
    "loc[5] = 400\n",
    "\n",
    "anom[89] = True\n",
    "type_anom[89] = 4\n",
    "loc[89] = 200\n",
    "\n",
    "anom[99] = True\n",
    "type_anom[99] = 4\n",
    "loc[99] = 100  \n",
    "\n",
    "anom = [False] * n_appr + anom\n",
    "type_anom = [-1] * n_appr + type_anom\n",
    "loc = [-1] * n_appr + loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_anom = list(np.where(np.asarray(anom))[0]) # Indices des anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fenetres(liste_comp, N, anom, loc):\n",
    "    serie = []\n",
    "    #origine = []\n",
    "    ind_debut = []\n",
    "    valeurs = []\n",
    "    anom_fen = []\n",
    "    for i, val, loc_i in zip(ind_recupere, liste_comp, loc):\n",
    "        # Liste des fenêtres de l'enregistrement\n",
    "        fenetres = [val[i * N:(i + 1) * N] for i in range((len(val) + N - 1) // N ) if len(val[i * N:(i + 1) * N]) == N]\n",
    "        nb_fen = len(fenetres)\n",
    "        valeurs += fenetres\n",
    "        anom_fen_i = [False] * nb_fen\n",
    "        pos_anom_deb_fen = loc_i // N\n",
    "        pos_anom_fin_fen = (loc_i + 55) // N\n",
    "        if loc_i > -1:\n",
    "            try:\n",
    "                for pos in range(pos_anom_deb_fen, pos_anom_fin_fen + 1):\n",
    "                    anom_fen_i[pos] = True\n",
    "\n",
    "            except IndexError:\n",
    "                pass\n",
    "                \"\"\"Cette erreur est levée lorsque l'anomalie se trouve en fin de série, dans une plage qui n'a pas été capturée \n",
    "                par une des fenêtres. On peut donc l'ignorer et continuer le traitement. Ce cas est de toute façon très rare\n",
    "                dans nos données.\"\"\"\n",
    "        anom_fen += anom_fen_i\n",
    "        ind_debut += list(range(0, nb_fen * N, N))\n",
    "        serie += [i] * nb_fen\n",
    "        \"\"\"if i < 300:\n",
    "            origine += [\"appr\"] * nb_fen\n",
    "        else:\n",
    "            origine += [\"test\"] * nb_fen\"\"\"\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(data={\"id\" : list(range(len(serie))), \"serie\" : serie, \"ind_debut\" : ind_debut, \"valeurs\" : valeurs, \"anom\" : anom_fen})\n",
    "        \n",
    "    return df.set_index([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80\n",
    "data_fenetres = df_fenetres(liste_propre, N, anom, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_anom = list(data_fenetres[data_fenetres[\"anom\"]][\"serie\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Toutes les fenetres des séries contenant une anomalie\n",
    "data_ajout_anom = data_fenetres.loc[data_fenetres[\"serie\"].isin(ind_anom)] \n",
    "# On met un indice d'une grande puisance de 10 pour identifier plus facilement les fenetres ajoutees\n",
    "offset = 10 ** (int(np.log10(data_fenetres.index.values[-1])) + 1)\n",
    "\n",
    "df_supervise = data_fenetres\n",
    "for i in range(1,2):\n",
    "    data_ajout_anom.index += offset\n",
    "    data_ajout_anom.serie += offset\n",
    "    df_supervise = pd.concat([df_supervise, data_ajout_anom])\n",
    "    \n",
    "# df_supervise contient les données d'apprentissage + les données de tests + les séries anormales recopiées 4 fois\n",
    "# les séries recopiées ont pour indice leur indice de départ + k*offset pour k=1,..,4\n",
    "df_supervise.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anom_type(Type):\n",
    "    for num in df_supervise.index.values:\n",
    "        TS = df_supervise.loc[num]\n",
    "        loc = TS[\"loc\"]\n",
    "        serie = TS[\"valeurs\"]\n",
    "\n",
    "        if TS[\"type\"] == Type: \n",
    "            fig, ax = plt.subplots(figsize=(12, 7))\n",
    "            plt.title(\"Série numéro \" + str(num) + \", type \" + str(Type), size=20, color='r', fontweight='bold')\n",
    "\n",
    "            ax.plot(range(loc), serie[: loc], 'b')\n",
    "            ax.plot(range(loc - 1, loc + 56), serie[loc - 1 : loc + 56], 'r')\n",
    "            ax.plot(range(loc + 55, len(serie)), serie[loc + 55 :], 'b')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for T in range(1, 5):\n",
    "        plot_anom_type(T)\n",
    "except KeyError:\n",
    "    print(\"Marche plus avec le nouveau DataFrame, à adapter si besoin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes de Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Calcul des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervise[\"min\"] = list(map(min, df_supervise.valeurs))\n",
    "df_supervise[\"max\"] = list(map(max, df_supervise.valeurs))\n",
    "df_supervise[\"mean\"] = list(map(np.mean, df_supervise.valeurs))\n",
    "df_supervise[\"std\"] = list(map(np.std, df_supervise.valeurs))\n",
    "df_supervise[\"skew\"] = list(map(sps.skew, df_supervise.valeurs))\n",
    "df_supervise[\"kurt\"] = list(map(sps.kurtosis, df_supervise.valeurs))\n",
    "df_supervise[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), df_supervise.valeurs))\n",
    "df_supervise[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), df_supervise.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    df_supervise[col] = scaler.fit_transform(df_supervise[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_test = df_supervise.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_supervise[names_features], df_supervise[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(X_train, Y_train)\n",
    "print(1 - rfFit.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfFit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\"max_features\" : list(range(2, len(names_features) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_,rfOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfOpt.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_chap = rfOpt.predict(X_test)\n",
    "# matrice de confusion\n",
    "# Options pour normalize : all, index, column\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 5))\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[0], annot_kws={\"size\": 16}) # font size\n",
    "ax[0].set_title(\"Matrice de confusion normalisée \\n selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1].set_title(\"Matrice de confusion normalisée \\n selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire : 1,2% d'erreurs, c'est très faible mais si on regarde la matrice de confusion on voit que la prévision n'est en fait pas si efficace. En effet on observe beaucoup de faux négatifs, envion un tiers. On a pas contre quasi aucun faux positif.\n",
    "\n",
    "On teste la même chose mais sans dupliquer les anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fenetres[\"min\"] = list(map(min, data_fenetres.valeurs))\n",
    "data_fenetres[\"max\"] = list(map(max, data_fenetres.valeurs))\n",
    "data_fenetres[\"mean\"] = list(map(np.mean, data_fenetres.valeurs))\n",
    "data_fenetres[\"std\"] = list(map(np.std, data_fenetres.valeurs))\n",
    "data_fenetres[\"skew\"] = list(map(sps.skew, data_fenetres.valeurs))\n",
    "data_fenetres[\"kurt\"] = list(map(sps.kurtosis, data_fenetres.valeurs))\n",
    "data_fenetres[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), data_fenetres.valeurs))\n",
    "data_fenetres[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), data_fenetres.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    data_fenetres[col] = scaler.fit_transform(data_fenetres[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taille_test = data_fenetres.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_fenetres[names_features], data_fenetres[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(X_train, Y_train)\n",
    "print(1 - rfFit.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfFit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\"max_features\" : list(range(2, len(names_features) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - rfOpt.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_chap = rfFit.predict(X_test)\n",
    "# matrice de confusion\n",
    "# Options pour normalize : all, index, column\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 5))\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[0], annot_kws={\"size\": 16}) # font size\n",
    "ax[0].set_title(\"Matrice de confusion normalisée \\n selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1].set_title(\"Matrice de confusion normalisée \\n selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire : Le modèle répond quasi systématiquement Non, et donc se trompe très peu. C'est parfaitement inexploitable, il faut garder la version en dupliquant les anomalies ou trouver une autre idée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "fftCoeff =[]\n",
    "for x in df_supervise[\"valeurs\"]:\n",
    "    mx = np.mean(x)\n",
    "    x_centre = x - mx\n",
    "    #Apply fast Fourier transform\n",
    "    coeffsfft = np.abs(fft(x_centre))\n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "    \n",
    "fftCoeff = np.array(fftCoeff)\n",
    "print(fftCoeff.shape)\n",
    "\n",
    "#Coefficients seuillés\n",
    "prop_a_garder = 0.1\n",
    "nb_coeffs = int(fftCoeff.shape[1] * prop_a_garder)\n",
    "somme = np.sum(fftCoeff**2, axis=0)\n",
    "fftCoeff_seuil = np.zeros((0, nb_coeffs))\n",
    "ind_grands = np.argsort(somme)[-nb_coeffs :]\n",
    "fftCoeff_seuil = fftCoeff[:, ind_grands]\n",
    "\n",
    "print(fftCoeff_seuil.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fourier = pd.DataFrame(fftCoeff)\n",
    "df_Fourier_seuil = pd.DataFrame(fftCoeff_seuil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_Fourier.columns :\n",
    "    df_Fourier[col] = scaler.fit_transform(df_Fourier[col].values.reshape(-1, 1))\n",
    "for col in df_Fourier_seuil.columns :\n",
    "    df_Fourier_seuil[col] = scaler.fit_transform(df_Fourier_seuil[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients d'ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "wavelist=['haar', 'db2']\n",
    "\n",
    "wavelist=['haar', 'db2'] \n",
    "\n",
    "Coeff_ond_haar = []\n",
    "Coeff_ond_db2 = []\n",
    "\n",
    "for x in df_supervise[\"valeurs\"]:\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs_haar = pywt.wavedec(x, wavelist[0], level=4) \n",
    "    coeffs_flatten_haar, coeff_slices_haar = pywt.coeffs_to_array(coeffs_haar)\n",
    "    Coeff_ond_haar.append(coeffs_flatten_haar)\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs_db2 = pywt.wavedec(x, wavelist[1], level=4) \n",
    "    coeffs_flatten_db2, coeff_slices_db2 = pywt.coeffs_to_array(coeffs_db2)\n",
    "    Coeff_ond_db2.append(coeffs_flatten_db2)\n",
    "    \n",
    "    \n",
    "Coeff_ond_haar = np.array(Coeff_ond_haar)\n",
    "Coeff_ond_db2 = np.array(Coeff_ond_db2)\n",
    "\n",
    "print(Coeff_ond_haar.shape, Coeff_ond_db2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ond_haar = pd.DataFrame(Coeff_ond_haar)\n",
    "df_ond_db2 = pd.DataFrame(Coeff_ond_db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df_ond_haar.columns :\n",
    "#    df_ond_haar[col] = scaler.fit_transform(df_ond_haar[col].values.reshape(-1, 1))\n",
    "#for col in df_ond_db2.columns :\n",
    "#    df_ond_db2[col] = scaler.fit_transform(df_ond_db2[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive display\n",
    "from ipywidgets import interact, widgets, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "df_liste = [\"Features\",\n",
    "            \"Ondelettes_haar\",\n",
    "            \"Ondelettes_db2\",\n",
    "            \"Coefficients de Fourier\",\n",
    "            \"Coefficients de Fourier seuillés\"\n",
    "           ]\n",
    "\n",
    "dict_df = {\"Features\" : df_supervise[names_features],\n",
    "           \"Ondelettes_haar\" : df_ond_haar,\n",
    "           \"Ondelettes_db2\" : df_ond_db2,\n",
    "           \"Coefficients de Fourier\" : df_Fourier,\n",
    "           \"Coefficients de Fourier seuillés\" : df_Fourier_seuil\n",
    "          }\n",
    "\n",
    "taille_max = df_supervise.shape[0]\n",
    "print(taille_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(Choix_df=df_liste, taille_test=widgets.IntSlider(min=100, max=taille_max - 100, step=100, \n",
    "                                                           value=taille_max//3, continuous_update=False), \n",
    "          button=widgets.ToggleButton(description=\"Refresh\"))\n",
    "\n",
    "def RandomForest(Choix_df, taille_test, button):\n",
    "    df_coeff = dict_df[Choix_df]\n",
    "    #print(\"Proportion de fenêtres utilisées pour l'apprentissage : \", 1 - taille_test / df_coeff.shape[0])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_coeff, df_supervise[\"anom\"], test_size=taille_test)\n",
    "    \n",
    "    # définition des paramètres\n",
    "    \n",
    "    # apprentissage\n",
    "    \n",
    "    max_feat = 5\n",
    "    param = [{\"max_features\" : list(range(2, min(max_feat, df_coeff.shape[1]) + 1))}]\n",
    "    rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "\n",
    "    rfOpt = rf.fit(X_train, Y_train)\n",
    "    \n",
    "    #print(\"Erreur Out of bag : \", 1 - rfOpt.oob_score_)  # N'existe pas sur les objets GridSearchCV, hélas\n",
    "    # erreur de prévision sur le test\n",
    "    #print(\"Erreur de prévision sur le test : \", 1 - rfOpt.score(X_test, Y_test))\n",
    "    # paramètre optimal\n",
    "    #print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                    min_samples_leaf=1, max_features=rfOpt.best_params_['max_features'], \n",
    "                                    max_leaf_nodes=None, bootstrap=True, oob_score=True)\n",
    "    rfFit = forest.fit(X_train, Y_train)\n",
    "    \n",
    "    # prévision\n",
    "    y_chap = rfOpt.predict(X_test)\n",
    "    \n",
    "    \n",
    "    df_supervise[\"pred\"] = np.array([False] * df_supervise.shape[0])\n",
    "    for ind, ind_fen in enumerate(Y_test.index):\n",
    "        df_supervise.loc[ind_fen, \"pred\"] = y_chap[ind]\n",
    "        \n",
    "    ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "    print(\"Séries contenant une anomalie : \", ind_series_anom)\n",
    "    # matrice de confusion\n",
    "\n",
    "    table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False)\n",
    "    table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "    table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\")\n",
    "    table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "    sns.set(font_scale=1.4)\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "    sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})\n",
    "    ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "    sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16})\n",
    "    ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "    sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16})\n",
    "    ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "    sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16})\n",
    "    ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "    plt.show()\n",
    "\n",
    "    for num in ind_series_anom:\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        TS = df_supervise[(df_supervise[\"serie\"] == num)][\"valeurs\"].values\n",
    "        anoms = df_supervise[df_supervise[\"serie\"] == num][\"pred\"].values\n",
    "        title_obj = plt.title(\"Série numéro \" + str(num % offset), size=25)\n",
    "        for (i, x), anom in zip(enumerate(TS), anoms):\n",
    "\n",
    "            if i > 0:  # Raccordement\n",
    "                ax.plot([N * i - 1, N * i], [last, x[0]], \"br\"[int(anom)])\n",
    "\n",
    "            ax.plot(range(N * i, N * (i + 1)),  x, \"br\"[int(anom)])\n",
    "            last = x[-1]\n",
    "            if anom:\n",
    "                plt.setp(title_obj, color='r', fontweight=\"bold\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :**\n",
    "\n",
    "Très peu d'erreur avec les coefficients d'ondelettes (haar ou db2) et même parfois 0 erreur.\n",
    "\n",
    "Avec les coefficients de Fourier : résulats quasi identiques à ceux de Features, parfois meilleurs, parfois pires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A FINIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RandomForest sur coefficients d'ondelettes db2\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Coeff_ond_db2, df_supervise[\"anom\"],\n",
    "                                                    test_size=Coeff_ond_db2.shape[1] // 3)\n",
    "\n",
    "max_feat = 16\n",
    "param = [{\"max_features\" : list(range(2, min(max_feat, Coeff_ond_db2.shape[1]) + 1))}]\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500), param, cv=5, n_jobs=-1)\n",
    "rfOpt = rf.fit(X_train, Y_train)\n",
    "\n",
    "# erreur de prévision sur le test\n",
    "print(\"Erreur de prévision sur le test : \", 1 - rfOpt.score(X_test, Y_test))\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_, rfOpt.best_params_))\n",
    "\n",
    "# forest optimal\n",
    "forest = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, max_features=2, max_leaf_nodes=None, bootstrap=True,\n",
    "                                oob_score=True)\n",
    "rfFit = forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importance de chaque coefficient : \", rfFit.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_chap = rfOpt.predict(X_test)\n",
    "y_chap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = rfFit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients triés par ordre d'importance\n",
    "np.argsort(rfFit.feature_importances_)[::-1] #dans l'ordre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on ne garde que les 10 coefficients les plus importants pour reconstruire un signal avec anomalie\n",
    "seuil = np.sort(importance)[-10]\n",
    "valeurs = df_ond_db2.loc[6, :].values\n",
    "valeurs_seuil = np.array([v if imp >= seuil else 0 for imp, v in zip(importance, valeurs)])\n",
    "valeurs_seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pywt.waverecn(pywt.array_to_coeffs(valeurs_seuil, coeff_slices), 'db2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le signal d'origine\n",
    "plt.plot(np.array(df_supervise.loc[6, \"valeurs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester regression logistique\n",
    "Pouvoir visualiser l'anomalie\n",
    "Tester lissage spline ou supprimer les niveaux de détails les plus fins en ondelettes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervise[\"min\"] = list(map(min, df_supervise.valeurs))\n",
    "df_supervise[\"max\"] = list(map(max, df_supervise.valeurs))\n",
    "df_supervise[\"mean\"] = list(map(np.mean, df_supervise.valeurs))\n",
    "df_supervise[\"std\"] = list(map(np.std, df_supervise.valeurs))\n",
    "df_supervise[\"skew\"] = list(map(sps.skew, df_supervise.valeurs))\n",
    "df_supervise[\"kurt\"] = list(map(sps.kurtosis, df_supervise.valeurs))\n",
    "df_supervise[\"energy\"] = list(map(lambda x : sum(np.asarray(x)**2)/len(x), df_supervise.valeurs))\n",
    "df_supervise[\"average_cross\"] = list(map(lambda x : sum(1*(x > np.mean(x)))/len(x), df_supervise.valeurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "names_features = [\"min\", \"max\", \"mean\", \"std\", \"skew\", \"kurt\", \"energy\", \"average_cross\"]\n",
    "for col in names_features:\n",
    "    data_fenetres[col] = scaler.fit_transform(data_fenetres[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_test = df_supervise.shape[0] // 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_supervise[names_features], df_supervise[\"anom\"], test_size=taille_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Grille de valeurs du paramètre de pénalisaiton\n",
    "param=[{\"C\": [0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "logitL = GridSearchCV(LogisticRegression(penalty=\"l1\"), param, cv=5, n_jobs=-1)\n",
    "logitLasso = logitL.fit(X_train, Y_train)\n",
    "# Sélection du paramètre optimal\n",
    "logitLasso.best_params_[\"C\"]\n",
    "print(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" % (1.-logitLasso.best_score_,logitLasso.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des estimateurs\n",
    "logit= LogisticRegression(penalty=\"l1\")\n",
    "logitOpt=logit.fit(X_train, Y_train)\n",
    "# erreur sur l'échantillon test\n",
    "1-logitOpt.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"optimal\" obtenu est utilisé pour prédire l'échantillon test et estimer ainsi, sans biais, une erreur de prévision.\n",
    "\n",
    "La matrice de confusion croise les abomalies prédites avec celles effectivement présentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_chap = logitOpt.predict(X_test)\n",
    "df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "# matrice de confusion\n",
    "table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)  #for label size\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "LassoOpt=LogisticRegression(penalty=\"l1\",C=12)\n",
    "LassoOpt=LassoOpt.fit(X_train, Y_train)\n",
    "# Récupération des coefficients\n",
    "vect_coef=np.matrix.transpose(LassoOpt.coef_)\n",
    "vect_coef=vect_coef.ravel()\n",
    "#Affichage des 25 plus importants\n",
    "coef=pd.Series(abs(vect_coef),index=X_train.columns).sort_values(ascending=False)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "coef.plot(kind='bar')\n",
    "plt.title('Coeffients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les coefficients les plus importants dans le cas de features sont ceux de average_cross et skew. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grilles de valeurs du paramètre de pénalisation\n",
    "param=[{\"C\":[0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "logitR = GridSearchCV(LogisticRegression(penalty=\"l2\"), param, cv=5, n_jobs=-1)\n",
    "logitRidge = logitR.fit(X_train, Y_train)  \n",
    "# Sélection du paramètre optimal\n",
    "logitRidge.best_params_[\"C\"]\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1.-logitRidge.best_score_, logitRidge.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prévision\n",
    "y_chap = logitRidge.predict(X_test)\n",
    "df_supervise[\"pred\"] = np.concatenate((np.array([False] * (df_supervise.shape[0] - len(y_chap))), y_chap))\n",
    "ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "# matrice de confusion\n",
    "table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "sns.set(font_scale=1.4)  #for label size\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe ROC, Elle est utile pour comparer Lasso et Ridge \n",
    "from sklearn.metrics import roc_curve\n",
    "listMethod=[[\"Lasso\", logitLasso], [\"Ridge\", logitRidge]]\n",
    "\n",
    "for (name, method) in listMethod:\n",
    "    probas = method.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, probas[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1, label=str(name))\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient de Fourier et d'ondelettes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visulation par intéract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(Choix_df=df_liste, taille_test=widgets.IntSlider(min=100, max=taille_max - 100, step=100, \n",
    "                                                           value=taille_max//3, continuous_update=False), \n",
    "          button=widgets.ToggleButton(description=\"Refresh\"))\n",
    "\n",
    "def RLLasso(Choix_df, taille_test, button):\n",
    "    df_coeff = dict_df[Choix_df]\n",
    "    print(\"Proportion de fenêtres utilisées pour l'apprentissage : \", 1 - taille_test / df_coeff.shape[0])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_coeff, df_supervise[\"anom\"], test_size=taille_test)\n",
    "    \n",
    "    param = [{\"C\": [0.5,1,5,10,12,15,30]}]\n",
    "    logitL = GridSearchCV(LogisticRegression(penalty=\"l1\"), param, cv=5, n_jobs=-1)\n",
    "    logitLasso = logitL.fit(X_train, Y_train)\n",
    "    # Sélection du paramètre optimal\n",
    "    logitLasso.best_params_[\"C\"]\n",
    "    print(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" %\n",
    "          (1.-logitLasso.best_score_,logitLasso.best_params_))\n",
    "    \n",
    "    # définition des estimateurs\n",
    "    logit= LogisticRegression(penalty=\"l1\")\n",
    "    logitOpt = logit.fit(X_train, Y_train)\n",
    "    # erreur sur l'échantillon test\n",
    "    print(\"Erreur sur l'échantillon test : \", 1-logitOpt.score(X_test, Y_test))\n",
    "\n",
    "    \n",
    "    # prévision\n",
    "    y_chap = logitOpt.predict(X_test)\n",
    "    df_supervise[\"pred\"] = np.array([False] * df_supervise.shape[0])\n",
    "    for ind, ind_fen in enumerate(Y_test.index):\n",
    "        df_supervise.loc[ind_fen, \"pred\"] = y_chap[ind]\n",
    "        \n",
    "    ind_series_anom = np.unique(df_supervise[df_supervise[\"pred\"]][\"serie\"].values)\n",
    "    print(\"Séries contenant une anomalie : \", ind_series_anom)\n",
    "    # matrice de confusion\n",
    "    table = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=False) # margins=True, margins_name=\"Total\")\n",
    "    table_norm = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"all\")\n",
    "    table_norm_index = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"index\") # margins=True, margins_name=\"Total\")\n",
    "    table_norm_col = pd.crosstab(y_chap, Y_test, rownames=[\"Prédiction\"], colnames=[\"Vraie valeur\"], normalize=\"columns\")\n",
    "    sns.set(font_scale=1.4)  #for label size\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "    sns.heatmap(table, annot=True, cmap=\"Blues\", ax=ax[0, 0], annot_kws={\"size\": 16})  # font size\n",
    "    ax[0, 0].set_title(\"Matrice de confusion brute\")\n",
    "    sns.heatmap(table_norm, annot=True, cmap=\"Blues\", ax=ax[0, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[0, 1].set_title(\"Matrice de confusion normalisée\")\n",
    "    sns.heatmap(table_norm_index, annot=True, cmap=\"Blues\", ax=ax[1, 0], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 0].set_title(\"Matrice de confusion normalisée selon les lignes\")\n",
    "    sns.heatmap(table_norm_col, annot=True, cmap=\"Blues\", ax=ax[1, 1], annot_kws={\"size\": 16}) # font size\n",
    "    ax[1, 1].set_title(\"Matrice de confusion normalisée selon les colonnes\")\n",
    "    plt.show()\n",
    "    \n",
    "    for num in ind_series_anom:\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        TS = df_supervise[(df_supervise[\"serie\"] == num)][\"valeurs\"].values\n",
    "        anoms = df_supervise[df_supervise[\"serie\"] == num][\"pred\"].values\n",
    "        title_obj = plt.title(\"Série numéro \" + str(num % offset), size=25)\n",
    "        for (i, x), anom in zip(enumerate(TS), anoms):\n",
    "\n",
    "            if i > 0:  # Raccordement\n",
    "                ax.plot([N * i - 1, N * i], [last, x[0]], \"br\"[int(anom)])\n",
    "\n",
    "            ax.plot(range(N * i, N * (i + 1)),  x, \"br\"[int(anom)])\n",
    "            last = x[-1]\n",
    "            if anom:\n",
    "                plt.setp(title_obj, color='r', fontweight=\"bold\")\n",
    "    \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
