{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avancement projet Anomalies, 2 avril"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#Fonctions statistiques \n",
    "import scipy.stats\n",
    "\n",
    "# ACP\n",
    "import sklearn.decomposition as sd\n",
    "import sklearn.preprocessing as sp\n",
    "# FFT\n",
    "from scipy.fftpack import fft\n",
    "# Hierarchical clustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#Wavelet\n",
    "import pywt\n",
    "from pywt import wavedec\n",
    "from statsmodels.robust import mad\n",
    "# LOF\n",
    "import sklearn.neighbors as sn\n",
    "# Isolation Forest\n",
    "import sklearn.ensemble as se\n",
    "#One Class SVM\n",
    "import sklearn.svm as ssvm\n",
    "\n",
    "# Plot et Display\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Interactive display\n",
    "from ipywidgets import interact, widgets, interactive, fixed, interact_manual\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lit directement les données nettoyées et dont la longueur a été modifiée à 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X_1024', 'rb') as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    X_1024, ind = mon_depickler.load() #X_1024 : données  #ind : liste des indices des signaux\n",
    "n = len(X_1024) #nb de signaux\n",
    "liste_appr = list(np.asarray(X_1024)[np.asarray(ind) <= 299])\n",
    "liste_test = list(np.asarray(X_1024)[np.asarray(ind) > 299])\n",
    "n_appr = len(liste_appr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "for x in X_1024:\n",
    "    plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficients de Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftCoeff = []\n",
    "\n",
    "for x in X_1024 :\n",
    "    mx = np.mean(x)\n",
    "    x_centre = x - mx\n",
    "    #Apply fast Fourier transform\n",
    "    coeffsfft = np.abs(fft(x_centre))\n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "\n",
    "fftCoeff = np.array(fftCoeff)\n",
    "print(fftCoeff.shape)\n",
    "\n",
    "#Coefficients seuillés\n",
    "prop_a_garder = 0.1\n",
    "nb_coeffs = int(fftCoeff.shape[1] * prop_a_garder)\n",
    "somme = np.sum(fftCoeff**2, axis=0)\n",
    "fftCoeff_seuil = np.zeros((0, nb_coeffs))\n",
    "ind_grands = np.argsort(somme)[-nb_coeffs :]\n",
    "fftCoeff_seuil = fftCoeff[:, ind_grands]\n",
    "\n",
    "print(fftCoeff_seuil.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Décomposition en ondelettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue la décomposition en ondelettes pour chaque signal et on récupère 2 tableaux de coefficients, l'un avec tous les coefficients de chaque signal, l'autre avec les coefficients seuillés. On pourra réaliser la décomposition en ondelettes seuillés avec les modes `hard`, `soft`, `greater` ou `less`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist=['haar','db2'] \n",
    "wf = 'haar' #Choix de l'ondelette\n",
    "\n",
    "Coeff_ond = []\n",
    "Coeff_ondT = []\n",
    "for x in X_1024:\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs = pywt.wavedec(x,wf,level=8) \n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff_ond.append(coeffs_flatten)\n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(1024))\n",
    "    # Apply Threshold on 4 first levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if j<=3 else c for j,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    Coeff_ondT.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff_ond = np.array(Coeff_ond)\n",
    "Coeff_ondT = np.array(Coeff_ondT)\n",
    "print(Coeff_ond.shape, Coeff_ondT.shape)\n",
    "print(np.sum(Coeff_ond!=0), np.sum(Coeff_ondT!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix des coefficients d'ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficient de niveau 7 à 10:\n",
    "Coeff_ond7=Coeff_ond[:,128:]\n",
    "#Coefficient de niveau 1 à 6 : \n",
    "Coeff_ondA6=Coeff_ond[:,:128]\n",
    "#Coefficient de niveau 1 à 4 : \n",
    "Coeff_ondA4=Coeff_ond[:,:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('liste_propre', 'rb') as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    liste_comp, ind = mon_depickler.load() #liste_comp : données  #ind : liste des indices des signaux\n",
    "n = len(liste_comp) #nb de signaux\n",
    "liste_appr = list(np.asarray(liste_comp)[np.asarray(ind) <= 299])\n",
    "liste_test = list(np.asarray(liste_comp)[np.asarray(ind) > 299])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min, max\n",
    "- mean \n",
    "- écart type \n",
    "- Skewness \n",
    "- Kurtosis \n",
    "- Energy \n",
    "- Average Crossing \n",
    "\n",
    "A ajouter ?\n",
    "\n",
    "- Distribution spectrale d'énergie \n",
    "- Pourcentage d'extrema locaux \n",
    "\n",
    "https://arc.aiaa.org/doi/pdf/10.2514/6.2016-2430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeMin = [min(liste) for liste in liste_comp]\n",
    "listeMax = [max(liste) for liste in liste_comp]\n",
    "listeMean = [np.mean(liste) for liste in liste_comp]\n",
    "listeStd = [np.std(liste) for liste in liste_comp]\n",
    "listeSkewness = [scipy.stats.skew(liste) for liste in liste_comp]\n",
    "listeKurtosis = [scipy.stats.kurtosis(liste) for liste in liste_comp]\n",
    "listeEnergy = [sum(np.asarray(liste)**2)/len(liste) for liste in liste_comp]\n",
    "listeAverageCross = [sum(1*(liste > np.mean(liste)))/len(liste) for liste in liste_comp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {\"Min\": listeMin, \"Max\": listeMax, \"Moyenne\": listeMean, \"Ecart-type\": listeStd, \"Skewness\" : listeSkewness, \"Kurtosis\": listeKurtosis, \"Energie\": listeEnergy, \"Average_Crossing\": listeAverageCross}\n",
    "DataFeatures = pd.DataFrame(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataFeatures.iloc[: len(liste_appr), :]\n",
    "data_test = DataFeatures.iloc[len(liste_appr) :, :]\n",
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sd.PCA()\n",
    "data = DataFeatures[[\"Min\",\"Max\",\"Moyenne\",\"Ecart-type\",\"Skewness\",\"Kurtosis\",\"Energie\", \"Average_Crossing\"]]\n",
    "C = pca.fit_transform(sp.scale(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_ACP(X_acp,acp) :\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.bar(range(5), acp.explained_variance_ratio_[:5]*100, align='center', color='grey', ecolor='black')\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Pourcentage de variance expliquée \\n des premières composantes\", fontsize=20)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    box = ax.boxplot(X_acp[:, 0:10])\n",
    "    ax.set_title(\"Distribution des premières composantes\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_proj_ACP(X_acp, axe_1=0, axe_2=1, etiq=True) :\n",
    "    fig = plt.figure(figsize=(13,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    dict_color = {True : \"blue\", False : \"red\"}\n",
    "\n",
    "    for x, y, s in zip(X_acp[:,axe_1], X_acp[:,axe_2], range(n)) :\n",
    "        ax.plot(x,y,marker=\".\", color=dict_color[s < len(liste_appr)])\n",
    "        if etiq :\n",
    "            ax.text(x, y, str(s))\n",
    "       \n",
    "    ax.set_title(\"Projection des invididus sur les \\n  deux premières composantes\", fontsize=20)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='blue', label='Série du jeu d\\'apprentissage', markersize=10, linewidth=0),\n",
    "                       Line2D([0], [0], marker='.', color='red', label='Série du jeu de test', markersize=10, linewidth=0)]\n",
    "\n",
    "    ax.legend(handles=legend_elements)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_ACP(C,pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordonnées des variables\n",
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, data.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0,0,i,j,color='r')\n",
    "plt.axis((-1.2,1.2,-1.2,1.2))\n",
    "# cercle\n",
    "c=plt.Circle((0,0), radius=1, color='b', fill=False)\n",
    "ax.add_patch(c)\n",
    "ax.set_xlabel(\"Dim1 : \" + str(round(pca.explained_variance_ratio_[:10][0]*100,2))+ \"%\" ,size=25)\n",
    "ax.set_ylabel(\"Dim2 : \" + str(round(pca.explained_variance_ratio_[:10][1]*100,2)) + \"%\",size=25)\n",
    "ax.set_title(\"ACP des deux premières composantes\",size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proj_ACP(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OC-SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration du paramètre nu par recherche dichotomique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_prop = 30 / 297  # Pourcentage estimé d'outliers dans le jeu d'apprentissage\n",
    "a = 1.e-13\n",
    "b = 1\n",
    "gamma = (a + b) / 2\n",
    "niter = 0\n",
    "OCSVM = ssvm.OneClassSVM(kernel='rbf', nu=outlier_prop, gamma=gamma)\n",
    "y_pred = OCSVM.fit(data_train).predict(data_test)\n",
    "nb_out = np.asarray(y_pred)[np.asarray(y_pred) == 1].shape[0]\n",
    "while nb_out != 20 and niter < 1e3:\n",
    "    if nb_out < 20 :\n",
    "        b = gamma\n",
    "    else :\n",
    "        a = gamma\n",
    "    gamma = (a + b) / 2\n",
    "    OCSVM = ssvm.OneClassSVM(kernel='rbf', nu=outlier_prop, gamma=gamma)\n",
    "    y_pred = OCSVM.fit(data_train).predict(data_test)\n",
    "    nb_out = np.asarray(y_pred)[np.asarray(y_pred) == 1].shape[0]\n",
    "    niter += 1\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM = ssvm.OneClassSVM(kernel='rbf', nu=outlier_prop, gamma=gamma)\n",
    "y_pred = OCSVM.fit(data_train).predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anom = []\n",
    "for i, serie in enumerate(liste_test):\n",
    "    if y_pred[i] == 1:\n",
    "        anom.append(300 + i)\n",
    "        plt.plot(serie)\n",
    "        plt.title(\"Série numéro \" + str(300+i) + \", anomalie détectée\")\n",
    "        plt.show()\n",
    "    elif False:\n",
    "        plt.plot(serie)\n",
    "        plt.title(\"Série numéro \" + str(300+i))\n",
    "        plt.show()\n",
    "print(anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coeff_features = DataFeatures.values.tolist()\n",
    "#Coeff_appr = DataFeatures.iloc[: n_appr].values.tolist()\n",
    "#Coeff_test = DataFeatures.iloc[n_appr :].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des différents coefficients sur lesquels appliquer les différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste et dictionnaire des coefficients #Utile pour les fonctions interactives\n",
    "Coeff_liste=[\"Tous les coefficients d'ondelettes\",\n",
    "             \"Coefficients d'ondelettes, niveau 7\",\n",
    "             \"Coefficients d'ondelettes, niveaux 1 à 6\",\n",
    "             \"Coefficients d'ondelettes, niveau 1 à 4\",\n",
    "             \"Coefficients d'ondelettes seuillés\",\n",
    "             \"Coefficients de Fourier\",\n",
    "             \"Coefficients de Fourier seuillés\",\n",
    "             \"X_1024\",\n",
    "             \"Coeffs features\"]\n",
    "\n",
    "dict_coeff ={\"Tous les coefficients d'ondelettes\" : Coeff_ond,\n",
    "             \"Coefficients d'ondelettes, niveau 7\" : Coeff_ond7,\n",
    "             \"Coefficients d'ondelettes, niveaux 1 à 6\" : Coeff_ondA6,\n",
    "             \"Coefficients d'ondelettes, niveau 1 à 4\" : Coeff_ondA4, \n",
    "             \"Coefficients d'ondelettes seuillés\" : Coeff_ondT,\n",
    "             \"Coefficients de Fourier\" : fftCoeff,\n",
    "             \"Coefficients de Fourier seuillés\" : fftCoeff_seuil,\n",
    "             \"X_1024\" : X_1024,\n",
    "             \"Coeffs features\" : Coeff_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions d'affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_ACP(X_acp, acp) :\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.bar(range(10), acp.explained_variance_ratio_[:10]*100, align='center', color='grey', ecolor='black')\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Pourcentage de variance expliquée \\n des premières composantes\", fontsize=20)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    box = ax.boxplot(X_acp[:, 0:10])\n",
    "    ax.set_title(\"Distribution des premières composantes\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_proj_ACP(X_acp, axe_1=0, axe_2=1, etiq=True) :\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    dict_color = {True : \"blue\", False : \"red\"}\n",
    "\n",
    "    for x, y, s in zip(X_acp[:,axe_1], X_acp[:,axe_2], ind) :\n",
    "        ax.plot(x,y,marker=\".\", color=dict_color[s < 300]) #300 : longueur liste apprentissage\n",
    "        if etiq :\n",
    "            ax.text(x, y, str(s))\n",
    "       \n",
    "    ax.set_title(\"Projection des invididus sur les \\n  deux premières composantes\", fontsize=20)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='blue', label='Série du jeu d\\'apprentissage', markersize=10, linewidth=0),\n",
    "                       Line2D([0], [0], marker='.', color='red', label='Série du jeu de test', markersize=10, linewidth=0)]\n",
    "\n",
    "    ax.legend(handles=legend_elements)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(Choix_coeff=Coeff_liste)\n",
    "def ACP(Choix_coeff):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    acp = sd.PCA()\n",
    "    X_acp = acp.fit_transform(sp.scale(Coeff))\n",
    "    plot_var_ACP(X_acp, acp)\n",
    "    plot_proj_ACP(X_acp, axe_1=0, axe_2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ascendante hierarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(Z,p):\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    sch.dendrogram(Z, p, leaf_rotation=45.,leaf_font_size=15, truncate_mode=\"level\", labels=ind)  # font size for the x axis labels\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(Choix_coeff=Coeff_liste,p=widgets.IntSlider(min=1,max=50,step=1,value=20,continuous_update=False))\n",
    "def CAH(Choix_coeff,p):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    Z = sch.linkage(Coeff, 'single')\n",
    "    C = np.array([c[0] for c in sch.cut_tree(Z,5)])\n",
    "    CT = pd.DataFrame(list(C), columns=[\"HCA_cluster\"])\n",
    "    plot_dendrogram(Z,p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'affichage des anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_anomalies(ind_anomalies,ind_data = ind):\n",
    "    \"\"\"Permet d'afficher le bon indice de la série dans le cas où des series ont été supprimées du jeu de données\"\"\"\n",
    "    return [ind_data[i] for i in ind_anomalies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=20/len(liste_test)\n",
    "n_estimators=100\n",
    "\n",
    "@interact(Choix_coeff=Coeff_liste)\n",
    "def plot_IF_anomaly(Choix_coeff):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    Coeff_appr = Coeff[: n_appr]\n",
    "    Coeff_test = Coeff[n_appr :]\n",
    "    clf = se.IsolationForest(n_estimators=n_estimators, contamination=contamination, bootstrap=True, behaviour=\"new\", n_jobs=-1)\n",
    "    pred = clf.fit(Coeff_appr).predict(Coeff_test)\n",
    "    acp_ond = sd.PCA()\n",
    "    X_acp_ond = acp_ond.fit_transform(sp.scale(Coeff))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    pred_complet = [1] * n_appr + list(pred)\n",
    "    \n",
    "    for i, j, nom, s in zip(X_acp_ond[:,0], X_acp_ond[:,1], pred_complet, ind):\n",
    "        color = \"red\" if nom!=1  else \"grey\"\n",
    "        plt.plot(i, j, \"o\", color=color) \n",
    "        if nom!=1:\n",
    "            ax.text(i,j,str(s))\n",
    "    ax.set_title(\"Repésentation des atypiques sur la projection des 2 premières composantes de l'ACP\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Anomalies détectées : \", print_anomalies([i for i, x in enumerate(pred_complet) if x!=1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kernel=\"rbf\"\n",
    "#nu=30/len(liste_appr) # Pourcentage estimé d'outliers dans le jeu d'apprentissage\n",
    "gamma=1e-11\n",
    "\n",
    "@interact(Choix_coeff=Coeff_liste,nu=widgets.FloatSlider(min=0.01,max=1.0,step=0.01,value=0.05))\n",
    "def plot_OCSVM_anomaly(Choix_coeff,nu):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    Coeff_appr = Coeff[: n_appr]\n",
    "    Coeff_test = Coeff[n_appr :]\n",
    "    \n",
    "    OCS = ssvm.OneClassSVM(kernel=kernel, nu=nu, gamma=gamma)\n",
    "    pred = OCS.fit(Coeff_appr).predict(Coeff_test)\n",
    "    pred_complet = [1] * n_appr + list(pred)\n",
    "\n",
    "    acp_ond = sd.PCA()\n",
    "    X_acp_ond = acp_ond.fit_transform(sp.scale(Coeff))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for i, j, nom, s in zip(X_acp_ond[:,0], X_acp_ond[:,1], pred_complet, ind):\n",
    "        color = \"red\" if nom!=1  else \"grey\"\n",
    "        plt.plot(i, j, \"o\",color=color) \n",
    "        if nom!=1:\n",
    "            ax.text(i,j,str(s))\n",
    "    ax.set_title(\"Repésentation des atypiques sur la projection des 2 premières composantes de l'ACP\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Anomalies détectées : \", print_anomalies([i for i, x in enumerate(pred_complet) if x!=1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=20/len(liste_test)\n",
    "metric = \"euclidean\"\n",
    "#n_neighbors = 15\n",
    "\n",
    "@interact(Choix_coeff=Coeff_liste,n_neighbors=widgets.IntSlider(min=1,max=30,step=1,value=15))\n",
    "def plot_LOF_anomaly(Choix_coeff,n_neighbors):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    Coeff_appr = Coeff[: n_appr]\n",
    "    Coeff_test = Coeff[n_appr :]\n",
    "    \n",
    "    clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric, novelty=True)\n",
    "    pred = clf.fit(Coeff_appr).predict(Coeff_test)\n",
    "    pred_complet = [1] * n_appr + list(pred)\n",
    "\n",
    "    acp_ond = sd.PCA()\n",
    "    X_acp_ond = acp_ond.fit_transform(sp.scale(Coeff))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for i, j, nom, s in zip(X_acp_ond[:,0], X_acp_ond[:,1], pred_complet, ind):\n",
    "        color = \"red\" if nom!=1  else \"grey\"\n",
    "        plt.plot(i, j, \"o\",color=color) \n",
    "        if nom!=1:\n",
    "            ax.text(i,j,str(s))\n",
    "    ax.set_title(\"Repésentation des atypiques sur la projection des 2 premières composantes de l'ACP\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Anomalies détectées : \", print_anomalies([i for i,x in enumerate(pred_complet) if x!=1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des méthodes IF, OC-SVM et LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methode_liste = [\"Classification ascendante hierarchique\",\"Isolation Forest\", \"One-Class SVM\", \"Local Outlier Factor\"]\n",
    "p=20 #CAH\n",
    "contamination = 20 / len(liste_test) #IF, LOF\n",
    "n_neighbors = 15 #LOF\n",
    "nu = 0.05 #OC-SVM\n",
    "gamma= 1e-11#OC-SVM\n",
    "\n",
    "#A CONSERVER : peut etre utile pour faire le choix des parametres\n",
    "def f(**args):\n",
    "    return args\n",
    "\n",
    "@interact(Choix_coeff=Coeff_liste, methode=methode_liste)\n",
    "def plot_anomaly(Choix_coeff, methode):\n",
    "    Coeff=dict_coeff[Choix_coeff]\n",
    "    Coeff_appr = Coeff[: n_appr]\n",
    "    Coeff_test = Coeff[n_appr :]\n",
    "    \n",
    "    if methode==\"Classification ascendante hierarchique\":\n",
    "        Coeff=dict_coeff[Choix_coeff]\n",
    "        Z = sch.linkage(Coeff, 'single')\n",
    "        C = np.array([c[0] for c in sch.cut_tree(Z,5)])\n",
    "        plot_dendrogram(Z,p)\n",
    "    else :\n",
    "        \n",
    "        if methode==\"Local Outlier Factor\":\n",
    "            clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric, novelty=True)\n",
    "            pred = clf.fit(Coeff_appr).predict(Coeff_test)\n",
    "        elif methode==\"Isolation Forest\":\n",
    "            clf = se.IsolationForest(n_estimators=n_estimators, contamination=contamination, bootstrap=True, behaviour=\"new\", n_jobs=-1)\n",
    "            pred = clf.fit(Coeff_appr).predict(Coeff_test)\n",
    "        elif methode==\"One-Class SVM\":\n",
    "            OCS = ssvm.OneClassSVM(kernel=kernel, nu=nu, gamma=gamma)\n",
    "            pred = OCS.fit(Coeff_appr).predict(Coeff_test)\n",
    "        \n",
    "        pred_complet = [1] * n_appr + list(pred)\n",
    "\n",
    "        acp_ond = sd.PCA()\n",
    "        X_acp_ond = acp_ond.fit_transform(sp.scale(Coeff))\n",
    "    \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        for i, j, nom, s in zip(X_acp_ond[:,0], X_acp_ond[:,1], pred_complet, ind):\n",
    "            color = \"red\" if nom!=1  else \"grey\"\n",
    "            plt.plot(i, j, \"o\",color=color) \n",
    "            if nom!=1:\n",
    "                ax.text(i,j,str(s))\n",
    "        plt.show()\n",
    "    \n",
    "        print(\"Anomalies détectées : \", print_anomalies([i for i, x in enumerate(pred_complet) if x!=1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
